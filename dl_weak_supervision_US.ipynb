{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ksndBerUYL_"
      },
      "source": [
        "# Crop Yield Prediction - Deep Learning\n",
        "\n",
        "Use NUTS3 input data to produce NUTS3 crop yield forecasts. Aggregate forecasts to NUTS2 level and train model using weak supervision from NUTS2 yield statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF2EPBzXz7IP",
        "outputId": "c83bd695-4e17-4ca4-fd0c-9918a2a14591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_env = 'guanabana'\n",
        "\n",
        "from d2l import torch as d2l\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import functions as SparkF\n",
        "from pyspark.sql import types as SparkT\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[25]\")\\\n",
        "                            .config(\"spark.driver.memory\", \"24g\")\\\n",
        "                            .config(\"spark.driver.maxResultSize\", \"6g\")\\\n",
        "                            .config(\"spark.executor.memory\", \"24g\")\\\n",
        "                            .config(\"spark.network.timeout\", \"800s\")\\\n",
        "                            .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "# crop name to id mapping\n",
        "crop_id_dict = {\n",
        "    'grain maize': 2,\n",
        "    'sugar beet' : 6,\n",
        "    'sugarbeet' : 6,\n",
        "    'sugarbeets' : 6,\n",
        "    'sugar beets' : 6,\n",
        "    'total potatoes' : 7,\n",
        "    'potatoes' : 7,\n",
        "    'potato' : 7,\n",
        "    'winter wheat' : 90,\n",
        "    'soft wheat' : 90,\n",
        "    'sunflower' : 93,\n",
        "    'spring barley' : 95,\n",
        "}\n",
        "\n",
        "# crop id to name mapping\n",
        "crop_name_dict = {\n",
        "    2 : 'grain maize',\n",
        "    6 : 'sugarbeet',\n",
        "    7 : 'potatoes',\n",
        "    90 : 'soft wheat',\n",
        "    93 : 'sunflower',\n",
        "    95 : 'spring barley',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdmh5cvWm0yB"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pcqgv5_m2rF"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from pyspark.sql import Window\n",
        "\n",
        "# crop name and id mappings\n",
        "def cropNameToID(crop_id_dict, crop):\n",
        "  \"\"\"\n",
        "  Return id of given crop. Relies on crop_id_dict.\n",
        "  Return 0 if crop name is not in the dictionary.\n",
        "  \"\"\"\n",
        "  crop_lcase = crop.lower()\n",
        "  try:\n",
        "    crop_id = crop_id_dict[crop_lcase]\n",
        "  except KeyError as e:\n",
        "    crop_id = 0\n",
        "\n",
        "  return crop_id\n",
        "\n",
        "def cropIDToName(crop_name_dict, crop_id):\n",
        "  \"\"\"\n",
        "  Return crop name for given crop ID. Relies on crop_name_dict.\n",
        "  Return 'NA' if crop id is not found in the dictionary.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    crop_name = crop_name_dict[crop_id]\n",
        "  except KeyError as e:\n",
        "    crop_name = 'NA'\n",
        "\n",
        "  return crop_name\n",
        "\n",
        "def getYear(date_str):\n",
        "  \"\"\"Extract year from date in yyyyMMdd or dd/MM/yyyy format.\"\"\"\n",
        "  return SparkF.when(SparkF.length(date_str) == 8,\n",
        "                     SparkF.year(SparkF.to_date(date_str, 'yyyyMMdd')))\\\n",
        "                     .otherwise(SparkF.year(SparkF.to_date(date_str, 'dd/MM/yyyy')))\n",
        "\n",
        "def getMonth(date_str):\n",
        "  \"\"\"Extract month from date in yyyyMMdd or dd/MM/yyyy format.\"\"\"\n",
        "  return SparkF.when(SparkF.length(date_str) == 8,\n",
        "                     SparkF.month(SparkF.to_date(date_str, 'yyyyMMdd')))\\\n",
        "                     .otherwise(SparkF.month(SparkF.to_date(date_str, 'dd/MM/yyyy')))\n",
        "\n",
        "def getDay(date_str):\n",
        "  \"\"\"Extract day from date in yyyyMMdd or dd/MM/yyyy format.\"\"\"\n",
        "  return SparkF.when(SparkF.length(date_str) == 8,\n",
        "                     SparkF.dayofmonth(SparkF.to_date(date_str, 'yyyyMMdd')))\\\n",
        "                     .otherwise(SparkF.dayofmonth(SparkF.to_date(date_str, 'dd/MM/yyyy')))\n",
        "\n",
        "# 1-10: Dekad 1\n",
        "# 11-20: Dekad 2\n",
        "# > 20 : Dekad 3\n",
        "def getDekad(date_str):\n",
        "  \"\"\"Extract dekad from date in YYYYMMDD format.\"\"\"\n",
        "  month = getMonth(date_str)\n",
        "  day = getDay(date_str)\n",
        "  return SparkF.when(day < 30, (month - 1)* 3 +\n",
        "                     SparkF.ceil(day/10)).otherwise((month - 1) * 3 + 3)\n",
        "\n",
        "def getFilename(crop, yield_trend, early_season_end,\n",
        "                country=None, spatial_level=None, architecture=None):\n",
        "  \"\"\"Get filename based on input arguments\"\"\"\n",
        "  suffix = crop.replace(' ', '_')\n",
        "\n",
        "  if (country is not None):\n",
        "    suffix += '_' + country\n",
        "\n",
        "  if (spatial_level is not None):\n",
        "    suffix += '_' + spatial_level\n",
        "\n",
        "  if (yield_trend):\n",
        "    suffix += '_trend'\n",
        "  else:\n",
        "    suffix += '_notrend'\n",
        "\n",
        "  if (early_season_end < 0):\n",
        "    suffix += '_early' + str(early_season_end)\n",
        "\n",
        "  if (architecture is not None):\n",
        "    suffix += '-' + architecture\n",
        "\n",
        "  return suffix\n",
        "\n",
        "def getLogFilename(crop, yield_trend, early_season_end,\n",
        "                   country=None, architecture=None):\n",
        "  \"\"\"Get filename for experiment log\"\"\"\n",
        "  log_file = getFilename(crop, yield_trend, early_season_end,\n",
        "                         country=country,\n",
        "                         architecture=architecture)\n",
        "  return log_file + '.log'\n",
        "\n",
        "def getPredictionFilename(crop, yield_trend, early_season_end,\n",
        "                          country=None, spatial_level=None, architecture=None):\n",
        "  \"\"\"Get unique filename for predictions\"\"\"\n",
        "  pred_file = 'pred_'\n",
        "  suffix = getFilename(crop, yield_trend, early_season_end,\n",
        "                       country=country,\n",
        "                       spatial_level=spatial_level,\n",
        "                       architecture=architecture)\n",
        "  pred_file += suffix\n",
        "  return pred_file\n",
        "\n",
        "def printConfig(cyp_config, log_fh=None):\n",
        "  config_str = '\\nCurrent DL Configuration'\n",
        "  config_str += '\\n-------------------------'\n",
        "  for k in cyp_config:\n",
        "    conf_val = cyp_config[k]\n",
        "    if (not isinstance(conf_val, str)):\n",
        "      conf_val = str(conf_val)\n",
        "\n",
        "    config_str += '\\n' + k + ': ' + conf_val\n",
        "  \n",
        "  config_str += '\\n'\n",
        "  if (log_fh is not None):\n",
        "    log_fh.write(config_str)\n",
        "\n",
        "  print(config_str)\n",
        "\n",
        "def printPreprocessingInformation(df, data_source, id_cols,\n",
        "                                  order_cols, crop_season=None):\n",
        "  \"\"\"Print preprocessed data and additional debug information\"\"\"\n",
        "  df_regions = [reg[0] for reg in df.select(id_cols).distinct().collect()]\n",
        "  print(data_source , 'data available for', len(df_regions), 'region(s)')\n",
        "  if (crop_season is not None):\n",
        "    print('Season end information')\n",
        "    crop_season.orderBy(id_cols + ['FYEAR']).show(10)\n",
        "\n",
        "  print(data_source, 'data')\n",
        "  df.orderBy(order_cols).show(10)\n",
        "\n",
        "def getTrendWindowYields(df, id_col, trend_window):\n",
        "  \"\"\"Extract previous years' yield values to separate columns\"\"\"\n",
        "  sel_cols = [id_col, 'FYEAR', 'YIELD']\n",
        "  my_window = Window.partitionBy(id_col).orderBy('FYEAR')\n",
        "\n",
        "  yield_fts = df.select(sel_cols)\n",
        "  for i in range(trend_window):\n",
        "    yield_fts = yield_fts.withColumn('YIELD-' + str(i+1),\n",
        "                                     SparkF.lag(yield_fts.YIELD, i+1).over(my_window))\n",
        "    yield_fts = yield_fts.withColumn('YEAR-' + str(i+1),\n",
        "                                     SparkF.lag(yield_fts.FYEAR, i+1).over(my_window))\n",
        "\n",
        "  # drop columns withs null values\n",
        "  for i in range(trend_window):\n",
        "    yield_fts = yield_fts.filter(SparkF.col('YIELD-' + str(i+1)).isNotNull())\n",
        "\n",
        "  prev_yields = [ 'YIELD-' + str(i) for i in range(trend_window, 0, -1)]\n",
        "  prev_years = [ 'YEAR-' + str(i) for i in range(trend_window, 0, -1)]\n",
        "  sel_cols = [id_col, 'FYEAR'] + prev_years + prev_yields\n",
        "  yield_fts = yield_fts.select(sel_cols)\n",
        "\n",
        "  return yield_fts\n",
        "\n",
        "def getNumericIDS(src_df, sel_col, num_id_col):\n",
        "  \"\"\"Assigns monotonically increasing unique ids to selected col values\"\"\"\n",
        "  id_df = src_df.select(sel_col).distinct().orderBy(sel_col)\n",
        "  id_df = id_df.withColumn(num_id_col, SparkF.monotonically_increasing_id())\n",
        "\n",
        "  return id_df\n",
        "\n",
        "def NormalizedRMSE(y_true, y_pred):\n",
        "  y_true = y_true.astype('float64')\n",
        "  y_pred = y_pred.astype('float64')\n",
        "  return 100 * np.sqrt(mean_squared_error(y_true, y_pred))/np.mean(y_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJgYxi8L1w_9"
      },
      "source": [
        "## Data Preprocessor Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfUbfgid10FR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Window\n",
        "\n",
        "class CYPDataPreprocessor:\n",
        "  def __init__(self, spark):\n",
        "    self.spark = spark\n",
        "    self.verbose = 1\n",
        "\n",
        "  def extractYearDekad(self, df):\n",
        "    \"\"\"Extract year and dekad from date_col in yyyyMMdd format.\"\"\"\n",
        "    # Conversion to string type is required to make getYear(), getMonth() etc. work correctly.\n",
        "    # They use to_date() function to verify valid dates and to_date() expects the date column to be string.\n",
        "    df = df.withColumn('DATE', df['DATE'].cast(\"string\"))\n",
        "    df = df.select('*',\n",
        "                   getYear('DATE').alias('FYEAR'),\n",
        "                   getDekad('DATE').alias('DEKAD'))\n",
        "\n",
        "    # Bring FYEAR, DEKAD to the front\n",
        "    col_order = df.columns[:2] + df.columns[-2:] + df.columns[2:-2]\n",
        "    df = df.select(col_order).drop('DATE')\n",
        "    return df\n",
        "\n",
        "  def preprocessCSSF(self, cssf_df):\n",
        "    cssf_df = cssf_df.withColumnRenamed('year', 'FYEAR')\n",
        "    cssf_df = cssf_df.withColumnRenamed('dekad', 'DEKAD')\n",
        "    cssf_df = cssf_df.drop(*['LONTD', 'LATTD'])\n",
        "\n",
        "    return cssf_df\n",
        "\n",
        "  def preprocessMeteo(self, meteo_df):\n",
        "    \"\"\"\n",
        "    Calculate CWB.\n",
        "    \"\"\"\n",
        "    meteo_df = meteo_df.withColumn('CWB',\n",
        "                                   SparkF.bround(meteo_df['PREC'] - meteo_df['ET0'], 2))\n",
        "\n",
        "    meteo_df = meteo_df.withColumnRenamed('year', 'FYEAR')\n",
        "    meteo_df = meteo_df.withColumnRenamed('dekad', 'DEKAD')\n",
        "    meteo_df = meteo_df.drop(*['LONTD', 'LATTD'])\n",
        "\n",
        "    return meteo_df\n",
        "\n",
        "  def preprocessRemoteSensing(self, rs_df):\n",
        "    rs_df = rs_df.withColumnRenamed('year', 'FYEAR')\n",
        "    rs_df = rs_df.withColumnRenamed('dekad', 'DEKAD')\n",
        "    rs_df = rs_df.drop(*['LONTD', 'LATTD'])\n",
        "\n",
        "    return rs_df\n",
        "\n",
        "  def preprocessCropArea(self, area_df):\n",
        "    area_df = area_df.withColumn(\"FYEAR\", area_df[\"FYEAR\"].cast(SparkT.IntegerType()))\n",
        "    area_df = area_df.filter(area_df[\"CROP_AREA\"].isNotNull())\n",
        "    # convert crop area into ha\n",
        "    area_df = area_df.withColumn('CROP_AREA', SparkF.round(area_df['CROP_AREA'] * 0.404686, 3))\n",
        "\n",
        "    return area_df\n",
        "\n",
        "  def preprocessYield(self, yield_df, spatial_level='GRIDS'):\n",
        "    \"\"\"\n",
        "    Convert county yields to t/ha.\n",
        "    See https://www.ndwheat.com/buyers/chartsandstats/\n",
        "    \"\"\"\n",
        "    if (spatial_level == 'COUNTY'):\n",
        "      yield_df = yield_df.withColumn('YIELD', SparkF.round(yield_df['YIELD'] * 0.06725, 3))\n",
        "\n",
        "    yield_df = yield_df.withColumn(\"FYEAR\", yield_df[\"FYEAR\"].cast(SparkT.IntegerType()))\n",
        "    yield_df = yield_df.filter(yield_df['YIELD'] > 0.0)\n",
        "    return yield_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91RKRiDfsGdZ"
      },
      "source": [
        "## Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6kkDgvJsJFh"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "\n",
        "def loadDataFromCSVFile(spark, data_path, src, spatial_level, country_code):\n",
        "    \"\"\"\n",
        "    The implied filename for each source is:\n",
        "    <data_source>_<spatial_level>_<country_code>.csv\n",
        "    Examples: WOFOST_NUTS2_NL.csv.\n",
        "    Schema is inferred from the file. We might want to specify the schema at some point.\n",
        "    \"\"\"\n",
        "    if (country_code is not None):\n",
        "      datafile = data_path + '/' + src  + '_' + spatial_level + '_' + country_code + '.csv'\n",
        "    elif (spatial_level is not None):\n",
        "      datafile = data_path + '/' + src  + '_' + spatial_level + '.csv'\n",
        "    else:\n",
        "      datafile = data_path + '/' + src  + '.csv'\n",
        "\n",
        "    print('Data file name', '\"' + datafile + '\"')\n",
        "\n",
        "    df = spark.read.csv(datafile, header = True, inferSchema = True)\n",
        "    return df\n",
        "\n",
        "def loadAllData(spark, data_sources, data_path='.', country=None):\n",
        "  #################\n",
        "  # Load data     #\n",
        "  #################\n",
        "  data_dfs = {}\n",
        "  for src in data_sources:\n",
        "    spatial_level = data_sources[src]['spatial_level']\n",
        "    data_dfs[src] = loadDataFromCSVFile(spark, data_path, src, spatial_level, country)\n",
        "\n",
        "  data_sources_str = ''\n",
        "  for src in data_dfs:\n",
        "    data_sources_str = data_sources_str + src + ', '\n",
        "\n",
        "  # remove the comma and space from the end\n",
        "  print('Loaded data:', data_sources_str[:-2])\n",
        "  print('\\n')\n",
        "\n",
        "  return data_dfs\n",
        "\n",
        "def preprocessData(spark, data_dfs, data_sources,\n",
        "                   crop, season_crosses_calyear=False,\n",
        "                   early_season=False, early_season_end=0, print_debug=False):\n",
        "  ######################\n",
        "  # Preprocess Data    #\n",
        "  ######################\n",
        "  cyp_preprocessor = CYPDataPreprocessor(spark)\n",
        "  crop_season = None\n",
        "\n",
        "  # county_grids_df = data_dfs['COUNTY']\n",
        "  # w = Window.partitionBy('GRID_ID')\n",
        "  # county_grids_df = county_grids_df.withColumn('maxSHAPE_AREA', SparkF.max('TOTAL_AREA').over(w))\n",
        "  # county_grids_df = county_grids_df.filter(county_grids_df['TOTAL_AREA'] == county_grids_df['maxSHAPE_AREA'])\n",
        "  # county_grids_df = county_grids_df.drop(*['maxSHAPE_AREA', 'TOTAL_AREA'])\n",
        "  # # ['AR', 'MO', 'TN', 'KY', 'IL', 'IN', 'KS', 'OH', 'NE', 'IA', 'PA', 'MI', 'WI', 'SD', 'MN', 'ND']\n",
        "  # county_grids_df = county_grids_df.filter(SparkF.substring(county_grids_df['COUNTY_ID'], 1, 2) == 'IA')\n",
        "\n",
        "  for src in data_sources:\n",
        "    sel_cols = data_sources[src]['sel_cols']\n",
        "    spatial_level = data_sources[src]['spatial_level']\n",
        "    if ('GRID_ID' in sel_cols):\n",
        "      src_df = data_dfs[src] #.join(county_grids_df, ['GRID_ID']).drop('COUNTY_ID')\n",
        "    else:\n",
        "      src_df = data_dfs[src]\n",
        "\n",
        "    # crop productivity data (CSSF)\n",
        "    if (src == 'CSSF'):\n",
        "      cssf_df = cyp_preprocessor.preprocessCSSF(src_df)\n",
        "      assert (cssf_df is not None)\n",
        "      data_dfs[src] = cssf_df.select(sel_cols)\n",
        "\n",
        "    # meteo data\n",
        "    if ('METEO' in src):\n",
        "      meteo_df = cyp_preprocessor.preprocessMeteo(src_df)\n",
        "\n",
        "      assert (meteo_df is not None)\n",
        "      data_dfs[src] = meteo_df.select(sel_cols)\n",
        "\n",
        "    # remote sensing data\n",
        "    if (src == 'REMOTE_SENSING'):\n",
        "      rs_df = cyp_preprocessor.preprocessRemoteSensing(src_df)\n",
        "      assert (rs_df is not None)\n",
        "      data_dfs[src] = rs_df.select(sel_cols)\n",
        "\n",
        "    # soil data\n",
        "    if (src == 'SOIL'):\n",
        "      data_dfs['SOIL'] = src_df.select(sel_cols)\n",
        "\n",
        "    # crop area data\n",
        "    if (src == 'CROP_AREA'):\n",
        "      crop_area_df = cyp_preprocessor.preprocessCropArea(src_df)\n",
        "      data_dfs['CROP_AREA'] = crop_area_df.select(sel_cols)\n",
        "\n",
        "    # label data\n",
        "    if (src == 'YIELD'):\n",
        "      yield_df = cyp_preprocessor.preprocessYield(src_df,\n",
        "                                                  spatial_level=spatial_level)\n",
        "      data_dfs['YIELD'] = yield_df.select(sel_cols)\n",
        "\n",
        "  # Print debug information\n",
        "  for src in data_dfs:\n",
        "    src_df = data_dfs[src]\n",
        "    order_cols = data_sources[src]['order_cols']\n",
        "    if ('GRID_ID' in src_df.columns):\n",
        "      printPreprocessingInformation(src_df, src, ['GRID_ID'], order_cols)\n",
        "    elif (print_debug):\n",
        "      printPreprocessingInformation(src_df, src, ['COUNTY_ID'], order_cols)\n",
        "\n",
        "  return data_dfs\n",
        "\n",
        "def getLinearYieldTrend(pd_yield_ft_df, id_cols, trend_window):\n",
        "  \"\"\"Fits a linear trend model to yields from 5 previous years\"\"\"\n",
        "  join_cols = id_cols + ['FYEAR']\n",
        "  region_years = pd_yield_ft_df[join_cols].values\n",
        "  prev_year_cols = ['YEAR-' + str(i) for i in range(1, trend_window + 1)]\n",
        "  prev_yield_cols = ['YIELD-' + str(i) for i in range(1, trend_window + 1)]\n",
        "  window_years = pd_yield_ft_df[prev_year_cols].values\n",
        "  window_yields = pd_yield_ft_df[prev_yield_cols].values\n",
        "\n",
        "  yield_trend = []\n",
        "  for i in range(region_years.shape[0]):\n",
        "    coefs = np.polyfit(window_years[i, :], window_yields[i, :], 1)\n",
        "    yield_trend.append(float(np.round(coefs[0] * region_years[i, 1] + coefs[1], 2)))\n",
        "\n",
        "  pd_yield_ft_df['YIELD_TREND'] = yield_trend\n",
        "  drop_cols = ['YEAR-' + str(i) for i in range(1, 6)]\n",
        "  pd_yield_ft_df = pd_yield_ft_df.drop(columns=drop_cols)\n",
        "\n",
        "  return pd_yield_ft_df\n",
        "\n",
        "def combineInputData(data_sources, data_dfs,\n",
        "                     ts_data_sources,\n",
        "                     static_data_sources,\n",
        "                     high_res_id_col, low_res_id_col,\n",
        "                     trend_window=5,\n",
        "                     early_season_end=None,\n",
        "                     print_debug=False):\n",
        "  \"\"\"Combine dekadal and static data\"\"\"\n",
        "  input_min_year = 1900\n",
        "  input_max_year = date.today().year\n",
        "  for src in ts_data_sources:\n",
        "    input_df = data_dfs[src]\n",
        "    min_year = input_df.agg(SparkF.min('FYEAR')).collect()[0][0]\n",
        "    max_year = input_df.agg(SparkF.max('FYEAR')).collect()[0][0]\n",
        "    # max of min years (earliest year after join, not min of min)\n",
        "    if (min_year > input_min_year):\n",
        "      input_min_year = min_year\n",
        "    # min of max years (latest year after join, not max of max)\n",
        "    if (max_year < input_max_year):\n",
        "      input_max_year = max_year\n",
        "\n",
        "  # combine dekadal data\n",
        "  dekadal_df = None\n",
        "  for src in ts_data_sources:\n",
        "    input_df = data_dfs[src].select(data_sources[src]['sel_cols'])\n",
        "    input_df = input_df.filter((input_df['FYEAR'] >= input_min_year) &\n",
        "                               (input_df['FYEAR'] <= input_max_year))\n",
        "    if (dekadal_df is None):\n",
        "      dekadal_df = input_df\n",
        "    else:\n",
        "      dekadal_df = dekadal_df.join(input_df, data_sources[src]['order_cols'], 'full')\n",
        "      dekadal_df = dekadal_df.na.fill(0.0)\n",
        "\n",
        "  max_dekad = 36\n",
        "  if (early_season_end is not None):\n",
        "    # early_season_end is relative to harvest (so 0 or negative)\n",
        "    max_dekad += early_season_end\n",
        "    dekadal_df = dekadal_df.filter(dekadal_df['DEKAD'] <= max_dekad)\n",
        "\n",
        "  county_grids_df = data_dfs['COUNTY']\n",
        "  dekadal_cols = dekadal_df.columns\n",
        "  dekadal_df = dekadal_df.join(county_grids_df.select([low_res_id_col, high_res_id_col]),\n",
        "                                                      [high_res_id_col])\n",
        "  dekadal_df = dekadal_df.select([low_res_id_col] + dekadal_cols)\n",
        "\n",
        "  static_df = None\n",
        "  for src in static_data_sources:\n",
        "    input_df = data_dfs[src].select(data_sources[src]['sel_cols'])\n",
        "    if (static_df is None):\n",
        "      static_df = input_df\n",
        "    else:\n",
        "      static_df = static_df.join(input_df, data_sources[src]['order_cols'])\n",
        "\n",
        "  static_cols = static_df.columns\n",
        "  static_df = static_df.na.drop()\n",
        "  static_df = static_df.join(county_grids_df.select([low_res_id_col, high_res_id_col]),\n",
        "                                                    [high_res_id_col])\n",
        "  static_df = static_df.select([low_res_id_col] + static_cols)\n",
        "\n",
        "  label_df = data_dfs['YIELD']\n",
        "  crop_area_df = data_dfs['CROP_AREA']\n",
        "\n",
        "  # get trend feature values: basically values of 5 previous years\n",
        "  trend_ft_df = getTrendWindowYields(label_df, low_res_id_col, trend_window)\n",
        "  year_cols = ['YEAR-' + str(i) for i in range(1, trend_window + 1)]\n",
        "  trend_ft_df = trend_ft_df.drop(*year_cols)\n",
        "\n",
        "  # Training, test splits are decided based on label years.\n",
        "  country_years = sorted([yr[0] for yr in label_df.select('FYEAR').distinct().collect()])\n",
        "\n",
        "  # Align spatial units and years\n",
        "  label_df = label_df.join(static_df.select(low_res_id_col).distinct(), [low_res_id_col])\n",
        "  label_df = label_df.join(trend_ft_df.select([low_res_id_col, 'FYEAR']),\n",
        "                           [low_res_id_col, 'FYEAR'])\n",
        "  # NOTE: CROP_AREA is added to label_df\n",
        "  label_df = label_df.join(crop_area_df, [low_res_id_col, 'FYEAR'])\n",
        "  label_df = label_df.join(dekadal_df.select([low_res_id_col, 'FYEAR']).distinct(),\n",
        "                           [low_res_id_col, 'FYEAR'])\n",
        "  label_reg_years = label_df.select([low_res_id_col, 'FYEAR']).distinct()\n",
        "  trend_ft_df = trend_ft_df.join(label_reg_years, [low_res_id_col, 'FYEAR'])\n",
        "  dekadal_df = dekadal_df.join(label_reg_years, [low_res_id_col, 'FYEAR'])\n",
        "  label_regions = label_df.select(low_res_id_col).distinct()\n",
        "  static_df = static_df.join(label_regions, [low_res_id_col])\n",
        "  county_grids_df = county_grids_df.join(label_regions, [low_res_id_col])\n",
        "\n",
        "  # Create numeric ids for counties\n",
        "  label_id_df = getNumericIDS(label_df, low_res_id_col, 'id_y')\n",
        "  input_id_df = county_grids_df.join(label_id_df, ['COUNTY_ID']).drop('TOTAL_AREA')\n",
        "\n",
        "  # Add numeric id columns, remove id_col and reorder columns\n",
        "  label_num_id_cols = ['id_y']\n",
        "  label_join_cols = [low_res_id_col]\n",
        "  label_drop_cols = [low_res_id_col]\n",
        "  input_num_id_cols = ['id_y', high_res_id_col]\n",
        "  input_join_cols = [low_res_id_col, high_res_id_col]\n",
        "  input_drop_cols = [low_res_id_col]\n",
        "\n",
        "  # Add numeric id columns : DEKADAL\n",
        "  dekadal_df = dekadal_df.join(input_id_df, input_join_cols).drop(*input_drop_cols)\n",
        "  dekadal_df = dekadal_df.select(input_num_id_cols + \n",
        "                                 [c for c in dekadal_df.columns if c not in input_num_id_cols])\n",
        "  if (print_debug):\n",
        "    print('\\n')\n",
        "    print('DEKADAL')\n",
        "    dekadal_df.orderBy(input_num_id_cols + ['FYEAR', 'DEKAD']).show(10)\n",
        "\n",
        "  # Add numeric id columns : TREND\n",
        "  trend_ft_df = trend_ft_df.join(label_id_df, label_join_cols).drop(*label_drop_cols)\n",
        "  trend_ft_df = trend_ft_df.select(label_num_id_cols +\n",
        "                                   [c for c in trend_ft_df.columns if c not in label_num_id_cols])\n",
        "  if (print_debug):\n",
        "    print('\\n')\n",
        "    print('TREND')\n",
        "    trend_ft_df.orderBy(label_num_id_cols + ['FYEAR']).show(10)\n",
        "\n",
        "  # Add numeric id columns : YIELD\n",
        "  label_df = label_df.join(label_id_df, label_join_cols).drop(*label_drop_cols)\n",
        "  label_df = label_df.select(label_num_id_cols +\n",
        "                             [c for c in label_df.columns if c not in label_num_id_cols])\n",
        "  if (print_debug):\n",
        "    print('\\n')\n",
        "    print('YIELD')\n",
        "    label_df.orderBy(label_num_id_cols + ['FYEAR']).show(10)\n",
        "\n",
        "  # Add numeric id columns : STATIC\n",
        "  # NOTE TOTAL_AREA comes from county_grids_df\n",
        "  static_df = static_df.join(county_grids_df, input_join_cols)\n",
        "  static_df = static_df.join(input_id_df, input_join_cols).drop(*input_drop_cols)\n",
        "  static_df = static_df.select(input_num_id_cols +\n",
        "                               [c for c in static_df.columns if c not in input_num_id_cols])\n",
        "  if (print_debug):\n",
        "    print('\\n')\n",
        "    print('STATIC')\n",
        "    static_df.orderBy(input_num_id_cols).show(10)\n",
        "\n",
        "  if (print_debug):\n",
        "    print('\\n')\n",
        "    print('NUMERIC_IDS')\n",
        "    input_id_df.orderBy(input_num_id_cols).show(10)\n",
        "    label_id_df.orderBy(label_num_id_cols).show(10)\n",
        "\n",
        "  combined_dfs = {\n",
        "      'DEKADAL' : dekadal_df.toPandas(),\n",
        "      'STATIC' : static_df.toPandas(),\n",
        "      'YIELD_TREND' : trend_ft_df.toPandas(),\n",
        "      'YIELD' : label_df.toPandas(),\n",
        "      'LABEL_NUMERIC_IDS' : label_id_df.toPandas(),\n",
        "      'INPUT_NUMERIC_IDS' : input_id_df.toPandas(),\n",
        "  }\n",
        "\n",
        "  return combined_dfs, country_years"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKWsYBQbquRs"
      },
      "source": [
        "## Training, Validation and Test Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiIg70PEq076"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class CYPTrainTestSplitter:\n",
        "  def __init__(self, verbose=False):\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def getTestYears(self, all_years, test_fraction=None, use_yield_trend=None):\n",
        "    num_years = len(all_years)\n",
        "    test_years = []\n",
        "    if (test_fraction is None):\n",
        "      test_fraction = self.test_fraction\n",
        "\n",
        "    if (use_yield_trend is None):\n",
        "      use_yield_trend = self.use_yield_trend\n",
        "\n",
        "    if (use_yield_trend):\n",
        "      # If test_year_start 15, years with index >= 15 are added to the test set\n",
        "      test_year_start = num_years - np.floor(num_years * test_fraction).astype('int')\n",
        "      test_years = all_years[test_year_start:]\n",
        "    else:\n",
        "      # If test_year_pos = 5, every 5th year is added to test set.\n",
        "      # indices start with 0, so test_year_pos'th year has index (test_year_pos - 1)\n",
        "      test_year_pos = np.floor(1/test_fraction).astype('int')\n",
        "      test_years = all_years[test_year_pos - 1::test_year_pos]\n",
        "\n",
        "    return test_years\n",
        "\n",
        "  # NOTE Y_train should include region_id, FYEAR as first two columns.\n",
        "  def getCustomKFoldValidationYears(self, all_years, num_folds=5, num_valid_years=1):\n",
        "    \"\"\"\n",
        "    Custom K-fold Validation Splits:\n",
        "    When using yield trend, we cannot do k-fold cross-validation. The custom\n",
        "    K-Fold validation splits data in time-ordered fashion. The test data\n",
        "    always comes after the training data.\n",
        "    \"\"\"\n",
        "    num_years = len(all_years)\n",
        "    num_train_years = num_years - (num_valid_years * num_folds)\n",
        "\n",
        "    custom_split_info = '\\nCustom sliding validation train, test splits'\n",
        "    custom_split_info += '\\n----------------------------------------------'\n",
        "\n",
        "    cv_valid_years = []\n",
        "    for k in range(num_folds):\n",
        "      test_years_start = num_train_years + (k * num_valid_years)\n",
        "      k_train_years = all_years[:test_years_start]\n",
        "      k_val_years = all_years[test_years_start:test_years_start + num_valid_years]\n",
        "      cv_valid_years.append(k_val_years)\n",
        "      k_train_years = [str(y) for y in k_train_years]\n",
        "      k_val_years = [str(y) for y in k_val_years]\n",
        "      custom_split_info += '\\nValidation set ' + str(k + 1) + ' training years: ' + ', '.join(k_train_years)\n",
        "      custom_split_info += '\\nValidation set ' + str(k + 1) + ' test years: ' + ', '.join(k_val_years)\n",
        "\n",
        "    custom_split_info += '\\n'\n",
        "    if (self.verbose):\n",
        "      print(custom_split_info)\n",
        "\n",
        "    return cv_valid_years"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDxuCEObX58A"
      },
      "source": [
        "## Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aRh3ijm5dy_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "# A dataset class for crop yield forecasting data\n",
        "# A dataset class for crop yield forecasting data\n",
        "class CYPMLDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Dataset class used to load features and labels for training and testing.\n",
        "  For more info about writing custom datasets classes check\n",
        "  https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  data_dfs : dictionary of input dataframes\n",
        "  yield_trend : data uses yield trend\n",
        "  early_season_end : early season prediction dekad (relative to harvest)\n",
        "  is_train : bool to differentiate training, validation and test sets\n",
        "  is_validation : bool to differentiate between training and validation sets\n",
        "  test_fraction : fraction of years to use for held-out testing\n",
        "  num_folds : number of folds for custom cv\n",
        "  num_valid_years : number of years in validation set\n",
        "  fold_iter : iteration number of cv\n",
        "  scaler_args : mean, std values (for each indicator) calculated using training dataset\n",
        "  \"\"\"\n",
        "  def __init__(self, data_dfs, country_years,\n",
        "               yield_trend=True, early_season_end=None,\n",
        "               is_train=True, is_validation=False, test_fraction=0.3,\n",
        "               num_folds=1, num_valid_years=5, fold_iter=0,\n",
        "               scaler_args=None,\n",
        "               print_debug=False, log_fh=None):\n",
        "\n",
        "    if (is_train and print_debug):\n",
        "      print('\\n----------------')\n",
        "      print('Training data')\n",
        "      print('----------------')\n",
        "    elif (is_validation and print_debug):\n",
        "      print('\\n------------------')\n",
        "      print('Validation data')\n",
        "      print('------------------')\n",
        "    elif (print_debug):\n",
        "      print('\\n-------------')\n",
        "      print('Test data:')\n",
        "      print('-------------')\n",
        "\n",
        "    pd_dekadal_df = data_dfs['DEKADAL']\n",
        "    max_dekad = 36\n",
        "    if (early_season_end is not None):\n",
        "      # early_season_end is relative to harvest (so 0 or negative)\n",
        "      max_dekad += early_season_end\n",
        "\n",
        "    pd_label_df = data_dfs['YIELD']\n",
        "    pd_trend_df = data_dfs['YIELD_TREND']\n",
        "    pd_static_df = data_dfs['STATIC']\n",
        "\n",
        "    # Static data\n",
        "    static_excl_cols = [ 'id_y', 'GRID_ID', 'TOTAL_AREA' ]\n",
        "    static_feature_cols = [ c for c in pd_static_df.columns if c not in static_excl_cols]\n",
        "    static_sel_cols =  static_excl_cols + static_feature_cols\n",
        "\n",
        "    # Dekadal data should have id_y, GRID_ID, FYEAR, DEKAD, ...\n",
        "    dekadal_feature_cols = list(pd_dekadal_df.columns.values)[4:]\n",
        "    self.dekadal_feature_cols = dekadal_feature_cols\n",
        "    max_dekad = 36\n",
        "    if (early_season_end is not None):\n",
        "      # early_season_end is relative to harvest (so 0 or negative)\n",
        "      max_dekad += early_season_end\n",
        "\n",
        "    self.max_dekad = max_dekad\n",
        "    # Trend data should have id_y, FYEAR, ...\n",
        "    trend_feature_cols = list(pd_trend_df.columns.values)[2:]\n",
        "    # For labels, we want to keep all columns. CROP_AREA is included in pd_label_df\n",
        "    label_cols = list(pd_label_df.columns.values)\n",
        "\n",
        "    if (print_debug):\n",
        "      assert (log_fh is not None)\n",
        "      feature_cols_info = '\\n'\n",
        "      feature_cols_info += '\\nDekadal features: ' + ', '.join(dekadal_feature_cols)\n",
        "      feature_cols_info += '\\nOther features: ' + ', '.join(static_feature_cols)\n",
        "      feature_cols_info += '\\nTrend features: ' + ', '.join(trend_feature_cols)\n",
        "      feature_cols_info += '\\nLabel columns: ' + ', '.join(label_cols[2:])\n",
        "      print(feature_cols_info)\n",
        "      log_fh.write(feature_cols_info + '\\n')\n",
        "\n",
        "    self.input_id_df = data_dfs['INPUT_NUMERIC_IDS']\n",
        "    # in the baseline, test years are determined based on all years available.\n",
        "    select_years = self.selectYears(country_years, is_train, is_validation, test_fraction,\n",
        "                                    num_folds, num_valid_years, fold_iter,\n",
        "                                    yield_trend)\n",
        "\n",
        "    min_trend_year = pd_trend_df['FYEAR'].min()\n",
        "    min_dek_year = pd_dekadal_df['FYEAR'].min()\n",
        "    select_years = [int(yr) for yr in select_years]\n",
        "    # In case of training, filter earlier years not in other data.\n",
        "    if (is_train):\n",
        "      select_years = [ yr for yr in select_years if ((yr >= min_trend_year) and (yr >= min_dek_year))]\n",
        "\n",
        "    if (is_train and print_debug):\n",
        "      train_info = '\\n Training years: ' + ', '.join([str(yr) for yr in select_years])\n",
        "      log_fh.write(train_info + '\\n')\n",
        "      print(train_info)\n",
        "    elif (is_validation and print_debug):\n",
        "      valid_info = '\\n Validation years: ' + ', '.join([str(yr) for yr in select_years])\n",
        "      log_fh.write(valid_info + '\\n')\n",
        "      print(valid_info)\n",
        "    elif (print_debug):\n",
        "      test_info = '\\n Test years: ' + ', '.join([str(yr) for yr in select_years])\n",
        "      log_fh.write(test_info + '\\n')\n",
        "      print(test_info)\n",
        "\n",
        "    pd_label_df = pd_label_df[pd_label_df['FYEAR'].isin(select_years)]\n",
        "    self.Y = pd_label_df[label_cols].values\n",
        "    self.pd_trend_df = pd_trend_df[pd_trend_df['FYEAR'].isin(select_years)]\n",
        "    self.pd_dekadal_df = pd_dekadal_df[pd_dekadal_df['FYEAR'].isin(select_years)]\n",
        "    self.pd_static_df = pd_static_df[static_sel_cols]\n",
        "\n",
        "    # Normalize data\n",
        "    if (is_train and (scaler_args is not None)):\n",
        "      for dek_col in dekadal_feature_cols:\n",
        "        scaler_args[dek_col] = [self.pd_dekadal_df[dek_col].mean(), self.pd_dekadal_df[dek_col].std()]\n",
        "\n",
        "      for trend_col in trend_feature_cols:\n",
        "        scaler_args[trend_col] = [self.pd_trend_df[trend_col].mean(), self.pd_trend_df[trend_col].std()]\n",
        "\n",
        "      for st_col in static_feature_cols:\n",
        "        scaler_args[st_col] = [self.pd_static_df[st_col].mean(), self.pd_static_df[st_col].std()]\n",
        "\n",
        "    if (scaler_args is not None):\n",
        "      for dek_col in dekadal_feature_cols:\n",
        "        avg_val, std_val = scaler_args[dek_col][0], scaler_args[dek_col][1]\n",
        "        self.pd_dekadal_df[dek_col] = (self.pd_dekadal_df[dek_col] - avg_val)/std_val\n",
        "\n",
        "      for trend_col in trend_feature_cols:\n",
        "        avg_val, std_val = scaler_args[trend_col][0], scaler_args[trend_col][1]\n",
        "        self.pd_trend_df[trend_col] = (self.pd_trend_df[trend_col] - avg_val)/std_val\n",
        "\n",
        "      for st_col in static_feature_cols:\n",
        "        avg_val, std_val = scaler_args[st_col][0], scaler_args[st_col][1]\n",
        "        self.pd_static_df[st_col] = (self.pd_static_df[st_col] - avg_val)/std_val\n",
        "\n",
        "    # create pivot tables\n",
        "    self.pd_dekadal_df = self.pd_dekadal_df.pivot_table(values=dekadal_feature_cols,\n",
        "                                                        index=[\"id_y\", \"GRID_ID\", \"FYEAR\"],\n",
        "                                                        columns=[\"DEKAD\"],\n",
        "                                                        fill_value=0.0)\n",
        "    self.pd_trend_df = self.pd_trend_df.pivot_table(values=trend_feature_cols,\n",
        "                                                    index=[\"id_y\", \"FYEAR\"],\n",
        "                                                    fill_value=0.0)\n",
        "    self.pd_total_area_df = self.pd_static_df.pivot_table(values=['TOTAL_AREA'],\n",
        "                                                      index=[\"id_y\", \"GRID_ID\"],\n",
        "                                                      fill_value=0.0)\n",
        "    self.pd_static_df = self.pd_static_df.pivot_table(values=static_feature_cols,\n",
        "                                                      index=[\"id_y\", \"GRID_ID\"],\n",
        "                                                      fill_value=0.0)\n",
        "\n",
        "    if ((self.Y is not None) and print_debug):\n",
        "      data_info = '\\n'\n",
        "      dekadal_data_shape = [len(self.pd_dekadal_df.index), max_dekad, len(dekadal_feature_cols)]\n",
        "      trend_data_shape = [len(self.pd_trend_df.index), len(trend_feature_cols)]\n",
        "      static_data_shape = [len(self.pd_static_df.index), len(static_feature_cols)]\n",
        "      data_info += '\\nDekadal data: ' + ', '.join([ str(x) for x in dekadal_data_shape])\n",
        "      data_info += '\\nOther feature data: ' + ', '.join([ str(x) for x in static_data_shape])\n",
        "      data_info += '\\nTrend feature data: ' + ', '.join([ str(x) for x in trend_data_shape])\n",
        "      data_info += '\\nLabel data: ' + ', '.join([ str(x) for x in self.Y.shape ])\n",
        "      print(data_info)\n",
        "      log_fh.write(data_info + '\\n')\n",
        "\n",
        "  def selectYears(self, all_years, is_train, is_validation, test_fraction,\n",
        "                  num_folds, num_valid_years, fold_iter,\n",
        "                  yield_trend=True):\n",
        "    \"\"\"Get selected train OR validation OR test years\"\"\"\n",
        "    trts_splitter = CYPTrainTestSplitter()\n",
        "    test_years = trts_splitter.getTestYears(all_years, test_fraction=test_fraction,\n",
        "                                            use_yield_trend=yield_trend)\n",
        "\n",
        "    if ((not is_train) and (not is_validation)):\n",
        "      return test_years\n",
        "\n",
        "    train_years = [yr for yr in all_years if yr not in test_years]\n",
        "    if (num_valid_years == 0):\n",
        "      return train_years\n",
        "\n",
        "    custom_valid_years = trts_splitter.getCustomKFoldValidationYears(train_years,\n",
        "                                                                     num_folds=num_folds,\n",
        "                                                                     num_valid_years=num_valid_years)\n",
        "    validation_years = custom_valid_years[fold_iter]\n",
        "    train_years = [yr for yr in train_years if yr < validation_years[0]]\n",
        "    select_years = train_years if is_train else validation_years\n",
        "\n",
        "    return select_years\n",
        "\n",
        "  def getAverageValue(self, indicator='YIELD'):\n",
        "    # self.Y has YIELD, CROP_AREA at the end\n",
        "    if (indicator == 'YIELD'):\n",
        "      return torch.from_numpy(np.array(np.mean(self.Y[:, -2]), dtype='float64'))\n",
        "    elif (indicator == 'CROP_AREA'):\n",
        "      return torch.from_numpy(np.array(np.mean(self.Y[:, -1]), dtype='float64'))\n",
        "    else:\n",
        "      return torch.zeros(1)\n",
        "\n",
        "  def getStaticFeatureCols(self):\n",
        "    return self.static_feature_cols\n",
        "\n",
        "  def __len__(self):\n",
        "    if (self.Y is None):\n",
        "      return 0\n",
        "\n",
        "    return self.Y.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    Returns data for given idx, which selects a specific id_y and FYEAR\n",
        "    sel_X_dek : Dekadal (time series) data\n",
        "    sel_X_rest : Other feature data (mostly static)\n",
        "    sel_X_trend : Trend features (yields of 5 previous years)\n",
        "    sel_Y : Yield for given county and year\n",
        "    sel_crop_area : crop area for given county and year\n",
        "    sel_grid_ids : grids included in selected COUNTY_ID\n",
        "    \"\"\"\n",
        "    assert (idx < self.Y.shape[0])\n",
        "    sel_id_y = self.Y[idx, 0]\n",
        "    sel_year = self.Y[idx, 1]\n",
        "    sel_grid_ids = self.input_id_df[self.input_id_df['id_y'] == sel_id_y]['GRID_ID'].values\n",
        "    sel_X_dekadal = None\n",
        "    sel_X_static = None\n",
        "    valid_gd_idxs = []\n",
        "    for i, gd in enumerate(sel_grid_ids):\n",
        "      try:\n",
        "        X_dek = self.pd_dekadal_df.loc[(sel_id_y, gd, sel_year)].values\n",
        "        X_dek = X_dek.reshape((len(self.dekadal_feature_cols), self.max_dekad)).T\n",
        "        X_dek = np.expand_dims(X_dek, axis=0)\n",
        "        X_static = self.pd_static_df.loc[(sel_id_y, gd)].values\n",
        "        X_static = np.expand_dims(X_static, axis=0)\n",
        "        X_total_area = self.pd_total_area_df.loc[(sel_id_y, gd)].values\n",
        "        X_total_area = np.expand_dims(X_total_area, axis=0)\n",
        "        X_static = np.append(X_total_area, X_static, axis=1)\n",
        "        valid_gd_idxs.append(i)\n",
        "        if (sel_X_dekadal is None):\n",
        "          sel_X_dekadal = X_dek\n",
        "          sel_X_static = X_static\n",
        "        else:\n",
        "          sel_X_dekadal = np.append(sel_X_dekadal, X_dek, axis=0)\n",
        "          sel_X_static = np.append(sel_X_static, X_static, axis=0)\n",
        "      except KeyError:\n",
        "        continue\n",
        "\n",
        "    # print(sel_X_dekadal.shape)\n",
        "    # print(sel_X_static.shape)\n",
        "    sel_X_trend = self.pd_trend_df.loc[(sel_id_y, sel_year)].values\n",
        "    # print(sel_X_trend.shape)\n",
        " \n",
        "    sel_X_dekadal = torch.from_numpy(np.array(sel_X_dekadal, dtype='float64'))\n",
        "    sel_X_trend = torch.from_numpy(np.array(sel_X_trend, dtype='float64'))\n",
        "    sel_X_static = torch.from_numpy(np.array(sel_X_static, dtype='float64'))\n",
        "\n",
        "    # NOTE: Label columns are id0, id_y, FYEAR, YIELD, CROP_AREA\n",
        "    sel_Y = torch.from_numpy(np.array(self.Y[idx, :-1], dtype='float64'))\n",
        "    sel_crop_area = torch.from_numpy(np.array(self.Y[idx, -1:], dtype='float64'))\n",
        "    sel_grid_ids = sel_grid_ids[valid_gd_idxs]\n",
        "    sel_grid_ids = torch.from_numpy(sel_grid_ids.reshape((sel_grid_ids.shape[0], 1)))\n",
        "\n",
        "    return sel_X_dekadal, sel_X_static, sel_X_trend, sel_Y, sel_crop_area, sel_grid_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks9-VxhciJ9m"
      },
      "source": [
        "## Evaluation method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXnpKymzEtkQ"
      },
      "outputs": [],
      "source": [
        "def predictionError(y_hat, y_true):\n",
        "  return torch.mean((y_hat - y_true)**2)\n",
        "\n",
        "def evaluatePredictions(net, test_loader, device='cpu'):\n",
        "  \"\"\"Evaluate predictions on dataset\"\"\"\n",
        "  net.eval()\n",
        "\n",
        "  y_low_res_full = None\n",
        "  y_high_res_full = None\n",
        "  for X_ts, X_rest, X_trend, y, county_crop_area, id_xs in test_loader:\n",
        "    X_ts, X_rest, X_trend  = X_ts.to(device), X_rest.to(device), X_trend.to(device)\n",
        "    y, county_crop_area, id_xs  = y.to(device), county_crop_area.to(device), id_xs.to(device)\n",
        "    X_ts = torch.squeeze(X_ts, dim=0)\n",
        "    X_rest = torch.squeeze(X_rest, dim=0)\n",
        "    X_trend = torch.squeeze(X_trend, dim=0)\n",
        "    id_xs = torch.squeeze(id_xs, 0)\n",
        "    sel_year = y[0, 1].repeat(id_xs.shape[0], 1)\n",
        "    sel_county = y[0, 0].repeat(id_xs.shape[0], 1)\n",
        "\n",
        "    # 1st column is TOTAL_AREA\n",
        "    grids_total_areas = X_rest[:, 0]\n",
        "    # skip TOTAL_AREA\n",
        "    X_rest = X_rest[:, 1:]\n",
        "    X_trend = X_trend.repeat(X_rest.shape[0], 1)\n",
        "    y_pred_grids = net(X_ts, X_rest, X_trend)\n",
        "\n",
        "    grids_crop_area_fr_preds = torch.special.expit(y_pred_grids[:, 0])\n",
        "    grids_crop_area_preds = torch.mul(grids_crop_area_fr_preds, grids_total_areas)\n",
        "    county_crop_area_pred = torch.sum(grids_crop_area_preds)\n",
        "    # Weights: normalize areas\n",
        "    grids_crop_area_pred_wts = grids_crop_area_preds/county_crop_area_pred\n",
        "\n",
        "    yield_preds_grids = y_pred_grids[:, 1]\n",
        "    yield_pred_county = torch.dot(yield_preds_grids, grids_crop_area_pred_wts)\n",
        "    yield_pred_county = yield_pred_county.reshape(1, 1)\n",
        "    county_crop_area_pred = county_crop_area_pred.reshape(1, 1)\n",
        "    y_low_res_iter = torch.cat((y, yield_pred_county, county_crop_area, county_crop_area_pred), 1)\n",
        "    yield_preds_grids = yield_preds_grids.reshape(yield_preds_grids.shape[0], 1)\n",
        "    y_high_res_iter = torch.cat((sel_county, id_xs, sel_year, yield_preds_grids), 1)\n",
        "\n",
        "    if (y_low_res_full is None):\n",
        "      y_low_res_full = y_low_res_iter\n",
        "      y_high_res_full = y_high_res_iter\n",
        "    else:\n",
        "      y_low_res_full = torch.cat((y_low_res_full, y_low_res_iter), 0)\n",
        "      y_high_res_full = torch.cat((y_high_res_full, y_high_res_iter), 0)\n",
        "\n",
        "  y_hat = y_low_res_full[:, -3]\n",
        "  y_true = y_low_res_full[:, -4]\n",
        "  nrmse_y = torch.sqrt(predictionError(y_hat, y_true))/torch.mean(y_true)\n",
        "\n",
        "  y_low_res_full = y_low_res_full.cpu().detach().numpy()\n",
        "  y_high_res_full = y_high_res_full.cpu().detach().numpy()\n",
        "  return y_low_res_full, y_high_res_full, nrmse_y.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FGP8puEikoK"
      },
      "source": [
        "## Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-dN1ctQimUo"
      },
      "outputs": [],
      "source": [
        "def grad_clipping(net, theta):\n",
        "  \"\"\"Clip the gradient.\"\"\"\n",
        "  if isinstance(net, nn.Module):\n",
        "    params = [p for p in net.parameters() if p.requires_grad]\n",
        "  else:\n",
        "    params = net.params\n",
        "\n",
        "  norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
        "  if norm > theta:\n",
        "    for param in params:\n",
        "      param.grad[:] *= theta / norm\n",
        "\n",
        "def train_epoch(net, train_dataset, train_loader, loss, loss_lambda,\n",
        "                updater, device='cpu'):\n",
        "  # Set the model to training mode\n",
        "  if isinstance(net, torch.nn.Module):\n",
        "      net.train()\n",
        "\n",
        "  # yield loss, crop area loss, no. of examples\n",
        "  metric = d2l.Accumulator(3)\n",
        "  mean_y = train_dataset.getAverageValue('YIELD').to(device)\n",
        "  mean_crop_area = train_dataset.getAverageValue('CROP_AREA').to(device)\n",
        "  train_y_full = None\n",
        "  for X_ts, X_rest, X_trend, y, county_crop_area, id_xs in train_loader:\n",
        "    X_ts, X_rest, X_trend = X_ts.to(device), X_rest.to(device), X_trend.to(device)\n",
        "    y, county_crop_area  = y.to(device), county_crop_area.to(device)\n",
        "    X_ts = torch.squeeze(X_ts, dim=0)\n",
        "    X_rest = torch.squeeze(X_rest, dim=0)\n",
        "    X_trend = torch.squeeze(X_trend, dim=0)\n",
        "\n",
        "    # 1st column is TOTAL_AREA\n",
        "    grids_total_areas = X_rest[:, 0]\n",
        "    # skip TOTAL_AREA\n",
        "    X_rest = X_rest[:, 1:]\n",
        "\n",
        "    X_trend = X_trend.repeat(X_ts.shape[0], 1)\n",
        "    y_pred_grids = net(X_ts, X_rest, X_trend)\n",
        "    # squeeze crop area fraction predictions to [0, 1]\n",
        "    grids_crop_area_fr_preds = torch.special.expit(y_pred_grids[:, 0])\n",
        "    grids_crop_area_preds = torch.mul(grids_crop_area_fr_preds, grids_total_areas)\n",
        "    # Weights: normalize areas\n",
        "    county_crop_area_pred = torch.sum(grids_crop_area_preds).flatten()\n",
        "    grids_crop_area_pred_wts = grids_crop_area_preds/county_crop_area_pred\n",
        "    yield_preds_grids = y_pred_grids[:, 1]\n",
        "    yield_pred_county = torch.dot(yield_preds_grids, grids_crop_area_pred_wts).flatten()\n",
        "    y_true = y[:, -1]\n",
        "    county_crop_area = county_crop_area.flatten()\n",
        "\n",
        "    # Compare crop area predictions with crop area statistics.\n",
        "    # If we use static weights, no need to compare.\n",
        "    # If we have static areas, then we can compare predicted areas with static area.\n",
        "    l_yield = torch.sqrt(loss(yield_pred_county, y_true))/mean_y\n",
        "    l_crop_area = torch.sqrt(loss(county_crop_area_pred, county_crop_area))/mean_crop_area\n",
        "    l = loss_lambda * l_yield + (1 - loss_lambda) * l_crop_area\n",
        "    updater.zero_grad()\n",
        "    l.backward()\n",
        "    grad_clipping(net, 1)\n",
        "    updater.step()\n",
        "\n",
        "    pred_error = predictionError(yield_pred_county, y_true)\n",
        "    # assert (pred_error > 0.0)\n",
        "    metric.add(float(l_yield), float(l_crop_area), 1)\n",
        "\n",
        "    yield_pred_county = yield_pred_county.reshape(y.shape[0], 1)\n",
        "    y_full_iter = torch.cat((y, yield_pred_county), 1)\n",
        "    if (train_y_full is None):\n",
        "      train_y_full = y_full_iter\n",
        "    else:\n",
        "      train_y_full = torch.cat((train_y_full, y_full_iter), 0)\n",
        "\n",
        "  # Return training loss and training NRMSE\n",
        "  y_hat = train_y_full[:, -1]\n",
        "  y_true = train_y_full[:, -2]\n",
        "  nrmse_y = torch.sqrt(predictionError(y_hat, y_true))/torch.mean(y_true)\n",
        "  return metric[0] / metric[2], metric[1] / metric[2], nrmse_y.item()\n",
        "\n",
        "def train(net, train_dataset, train_loader, test_loader,\n",
        "          loss, loss_lambda, updater, num_epochs,\n",
        "          early_stopping=False, device='cpu',\n",
        "          visualize=False, country=None, ymax=1.0):\n",
        "  if (visualize):\n",
        "    animator = d2l.Animator(xlabel='epoch',\n",
        "                            ylabel=('loss (' + country + ')') if country is not None else 'loss',\n",
        "                            xlim=[1, num_epochs], ylim=[0, ymax],\n",
        "                            legend=['yield loss', 'crop area loss', 'train error', 'test error'],\n",
        "                            figsize=(5,5))\n",
        "  test_error = 0\n",
        "  saved_test_errors = []\n",
        "  epochs_to_run = num_epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    train_metrics = train_epoch(net, train_dataset, train_loader, loss, loss_lambda, updater, device)\n",
        "    _, _, test_error = evaluatePredictions(net, test_loader, device)\n",
        "    # Early Stopping:\n",
        "    # Check if test error is more than last two errors.\n",
        "    if (early_stopping):\n",
        "      saved_test_errors.append(test_error)\n",
        "      if ((epoch > 3) and\n",
        "          (saved_test_errors[-1] > saved_test_errors[-2]) and\n",
        "          (saved_test_errors[-2] > saved_test_errors[-3])):\n",
        "        # (epoch - 2) + 1. +1 because of range(epochs_to_run)\n",
        "        epochs_to_run = epoch - 1\n",
        "        break\n",
        "\n",
        "    # print(epoch, test_error)\n",
        "    if (visualize):\n",
        "      animator.add(epoch + 1, train_metrics + (test_error,))\n",
        "\n",
        "  return test_error, epochs_to_run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-yqUcALlAeF"
      },
      "source": [
        "## LSTM RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tLOxawDlDuG"
      },
      "outputs": [],
      "source": [
        "# WOFOST : Dekadal (every 10 days) : 5 variables\n",
        "# WEATHER : Dekadal : 5 variables\n",
        "# REMOTE SENSING : Dekadal (every 10 days) : 1 variable\n",
        "\n",
        "# RNN\n",
        "#         WOFOST_V1 WOFOST_V2 ... WEATHER_V1 WEATHER_V2 ... FAPAR\n",
        "# Dekad 1\n",
        "# Dekad 2\n",
        "# ...\n",
        "# Dekad 36\n",
        "# Yield = one value\n",
        "\n",
        "# Trend Window\n",
        "# YEAR-5, YEAR-4, YEAR-3, YEAR-2, YEAR-1\n",
        "\n",
        "class CYPLSTMModel(nn.Module):\n",
        "  \"\"\"The RNN model.\"\"\"\n",
        "  def __init__(self, num_ts_features,\n",
        "               num_trend_features,\n",
        "               num_other_features,\n",
        "               ts_seq_len=36,\n",
        "               num_outputs=1):\n",
        "    super(CYPLSTMModel, self).__init__()\n",
        "\n",
        "    self.ts_rnns = nn.ModuleList()\n",
        "    self.num_ts_inputs = num_ts_features\n",
        "    self.num_rnn_layers = 1\n",
        "    self.rnn_hidden_size = 64\n",
        "\n",
        "    self.rnn = nn.LSTM(input_size=num_ts_features,\n",
        "                       hidden_size=self.rnn_hidden_size,\n",
        "                       num_layers=self.num_rnn_layers,\n",
        "                       batch_first=True)\n",
        "\n",
        "    num_all_features = self.rnn_hidden_size + num_trend_features + num_other_features\n",
        "    self.fc = nn.Linear(num_all_features, num_outputs)\n",
        "\n",
        "  def forward(self, X_ts, X_rest, X_trend):\n",
        "    ts_h, ts_state = self.rnn(X_ts)\n",
        "    ts_h_out = ts_state[0].view(-1, self.rnn.hidden_size)\n",
        "\n",
        "    # print(ts_h_out.shape, X_rest.shape, X_trend.shape)\n",
        "    all_features = torch.cat([ts_h_out, X_trend, X_rest], 1)\n",
        "    output = self.fc(all_features)\n",
        "\n",
        "    # print(output.shape)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHI4XA-gsYJ7"
      },
      "source": [
        "## Run Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYWLJsQv1EGp"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulYi8nUDnyjn",
        "outputId": "6b0c2589-672b-4c56-fbff-8ef0199286d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current DL Configuration\n",
            "-------------------------\n",
            "crop: grain maize\n",
            "season_crosses_calendar_year: False\n",
            "country_code: US\n",
            "input_spatial_level: GRIDS\n",
            "label_spatial_level: COUNTY\n",
            "data_path: /content\n",
            "output_path: /content\n",
            "use_yield_trend: True\n",
            "early_season_end_dekad: -6\n",
            "num_cv_folds: 1\n",
            "num_valid_years: 5\n",
            "test_fraction: 0.3\n",
            "architecture: LSTM\n",
            "debug_level: 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if (test_env == 'guanabana'):\n",
        "  cyp_config = {\n",
        "      'crop' : 'grain maize',\n",
        "      'season_crosses_calendar_year' : False,\n",
        "      'country_code' : 'US',\n",
        "      'input_spatial_level' : 'GRIDS',\n",
        "      'label_spatial_level' : 'COUNTY',\n",
        "      'high_res_id_col' : 'GRID_ID',\n",
        "      'low_res_id_col' : 'COUNTY_ID',\n",
        "      'data_path' : '../data',\n",
        "      'output_path' : '../output',\n",
        "      'use_yield_trend' : True,\n",
        "      'early_season_end_dekad' : -6,\n",
        "      'num_cv_folds' : 1,\n",
        "      'num_valid_years' : 5,\n",
        "      'test_fraction' : 0.3,\n",
        "      'architecture' : 'LSTM',\n",
        "      'debug_level' : 2,\n",
        "  }\n",
        "\n",
        "  crop = cyp_config['crop']\n",
        "  country = cyp_config['country_code']\n",
        "  use_yield_trend = cyp_config['use_yield_trend']\n",
        "  early_season_end = cyp_config['early_season_end_dekad']\n",
        "\n",
        "  output_path = cyp_config['output_path']\n",
        "  log_file = getLogFilename(crop, use_yield_trend, early_season_end,\n",
        "                            country=country,\n",
        "                            architecture=cyp_config['architecture'])\n",
        "  log_fh = open(output_path + '/' + log_file, 'w+')\n",
        "\n",
        "  if (cyp_config['debug_level'] > 1):\n",
        "    printConfig(cyp_config, log_fh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgYkzkrExu9Q"
      },
      "source": [
        "### County Trend Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxPWuQloxyGo",
        "outputId": "67b6a5d8-2aa6-4ef1-b306-c377fdc3b67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      COUNTY_ID  FYEAR  YIELD-5  YIELD-4  YIELD-3  YIELD-2  YIELD-1  YIELD_TREND\n",
            "10  AL_AUTAUGA   2013    5.582    6.927    4.439    2.690    7.471         6.67\n",
            "11  AL_AUTAUGA   2017    6.927    4.439    2.690    7.471    6.678         7.86\n",
            "12  AL_AUTAUGA   2018    4.439    2.690    7.471    6.678   11.486        11.53\n",
            "25  AL_BALDWIN   2013    7.061    8.339   10.888    4.432    8.292         7.65\n",
            "26  AL_BALDWIN   2014    8.339   10.888    4.432    8.292   10.491         9.00\n",
            "27  AL_BALDWIN   2015   10.888    4.432    8.292   10.491    9.341         9.58\n",
            "28  AL_BALDWIN   2016    4.432    8.292   10.491    9.341    9.899        12.09\n",
            "29  AL_BALDWIN   2017    8.292   10.491    9.341    9.899   10.283        10.68\n",
            "30  AL_BALDWIN   2018   10.491    9.341    9.899   10.283   10.895        10.71\n",
            "42  AL_BARBOUR   2013    5.044    6.927    7.330    5.340    8.043         7.95\n",
            "\n",
            "        GRID_ID  FYEAR  YIELD COUNTY_ID  SHAPE_AREA  YIELD_TREND\n",
            "16721  4540498   2013  7.085   AR_CLAY    4463.641        11.25\n",
            "25740  4540498   2014  6.419   AR_CLAY    4463.641        12.98\n",
            "10816  4540498   2015  7.414   AR_CLAY    4463.641        14.21\n",
            "49577  4540498   2016  8.032   AR_CLAY    4463.641        13.74\n",
            "30924  4540498   2017  8.173   AR_CLAY    4463.641        11.79\n",
            "37132  4540498   2018  8.218   AR_CLAY    4463.641        12.72\n",
            "16722  4544098   2013  0.216   AR_CLAY    9966.943        11.25\n",
            "25737  4544098   2014  0.274   AR_CLAY    9966.943        12.98\n",
            "10813  4544098   2015  0.022   AR_CLAY    9966.943        14.21\n",
            "49575  4544098   2016  0.245   AR_CLAY    9966.943        13.74\n",
            "\n",
            " US Trend NRMSE: 28.745558912465313\n"
          ]
        }
      ],
      "source": [
        "def evaluateCountyTrendAsGridPrediction(cyp_config):\n",
        "  crop_id = cropNameToID(crop_id_dict, cyp_config['crop'])\n",
        "  data_path = cyp_config['data_path']\n",
        "  output_path = cyp_config['output_path']\n",
        "  county_yield_df = spark.read.csv(data_path + '/' + 'YIELD_COUNTY_US.csv',\n",
        "                                   header = True, inferSchema = True)\n",
        "  # convert county yields to t/ha\n",
        "  # see https://www.ndwheat.com/buyers/chartsandstats/\n",
        "  county_yield_df = county_yield_df.withColumn('YIELD', SparkF.round(county_yield_df['YIELD'] * 0.06725, 3))\n",
        "  trend_ft_df = getTrendWindowYields(county_yield_df, 'COUNTY_ID', 5)\n",
        "  trend_ft_df = getLinearYieldTrend(trend_ft_df.toPandas(), ['COUNTY_ID'], 5)\n",
        "\n",
        "  grids_yield_df = spark.read.csv(data_path + '/' + 'YIELD_GRIDS_US.csv',\n",
        "                                  header = True, inferSchema = True)\n",
        "  grids_yield_df = grids_yield_df.groupBy(['GRID_ID', 'FYEAR']).agg(SparkF.max('YIELD').alias('YIELD'))\n",
        "  county_grids_df = spark.read.csv(data_path + '/' + 'COUNTY_GRIDS_US.csv',\n",
        "                                   header = True, inferSchema = True)\n",
        "  grids_yield_df = grids_yield_df.join(county_grids_df, 'GRID_ID')\n",
        "  pd_county_yield_df = county_yield_df.toPandas()\n",
        "  pd_grids_yield_df = grids_yield_df.toPandas()\n",
        "  test_fraction = 0.3\n",
        "  cn_all_years = sorted(pd_grids_yield_df['FYEAR'].unique())\n",
        "  num_years = len(cn_all_years)\n",
        "  test_year_start = num_years - np.floor(num_years * test_fraction).astype('int')\n",
        "  test_years = cn_all_years[test_year_start:]\n",
        "  pd_grids_yield_df = pd_grids_yield_df[pd_grids_yield_df['FYEAR'].isin(test_years)]\n",
        "  trend_ft_df = trend_ft_df[trend_ft_df['FYEAR'].isin(test_years)]\n",
        "  print('\\n', trend_ft_df.sort_values(by=['COUNTY_ID', 'FYEAR']).head(10).to_string())\n",
        "  pd_grids_yield_df = pd_grids_yield_df.merge(trend_ft_df[['COUNTY_ID', 'FYEAR', 'YIELD_TREND']],\n",
        "                                              on=['COUNTY_ID', 'FYEAR'])\n",
        "  print('\\n', pd_grids_yield_df.sort_values(by=['COUNTY_ID', 'GRID_ID', 'FYEAR']).head(10).to_string())\n",
        "  trend_nrmse = NormalizedRMSE(pd_grids_yield_df['YIELD'].values,\n",
        "                               pd_grids_yield_df['YIELD_TREND'].values)\n",
        "  print('\\n', cyp_config['country_code'], 'Trend NRMSE:', trend_nrmse)\n",
        "  pd_grids_yield_df.to_csv(output_path + '/NAIVE_TREND_PREDS_GRIDS.csv', index=False)\n",
        "\n",
        "if (test_env == 'guanabana'):\n",
        "  evaluateCountyTrendAsGridPrediction(cyp_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvJm0yk71CDg"
      },
      "source": [
        "### Load and preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAqMFsXv1Fkf",
        "outputId": "b37cb7e7-30c1-4e5d-9290-09d69256dd3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data file name \"/content/COUNTY_GRIDS_US.csv\"\n",
            "Data file name \"/content/CSSF_GRIDS_US.csv\"\n",
            "Data file name \"/content/METEO_GRIDS_US.csv\"\n",
            "Data file name \"/content/REMOTE_SENSING_GRIDS_US.csv\"\n",
            "Data file name \"/content/CROP_AREA_COUNTY_US.csv\"\n",
            "Data file name \"/content/YIELD_COUNTY_US.csv\"\n",
            "Loaded data: COUNTY, CSSF, METEO, REMOTE_SENSING, CROP_AREA, YIELD\n",
            "\n",
            "\n",
            "COUNTY data available for 114702 region(s)\n",
            "COUNTY data\n",
            "+-----------------+-------+----------------+\n",
            "|        COUNTY_ID|GRID_ID|      TOTAL_AREA|\n",
            "+-----------------+-------+----------------+\n",
            "|AK_ALEUTIANS_EAST|5180538|1178.13105782414|\n",
            "|AK_ALEUTIANS_EAST|5180539|1868.66009753263|\n",
            "|AK_ALEUTIANS_EAST|5180540|99.0924010861821|\n",
            "|AK_ALEUTIANS_EAST|5180541|300.309353168362|\n",
            "|AK_ALEUTIANS_EAST|5180544|191.021480855189|\n",
            "|AK_ALEUTIANS_EAST|5180545|843.745212641644|\n",
            "|AK_ALEUTIANS_EAST|5180547|149.339434947377|\n",
            "|AK_ALEUTIANS_EAST|5184139|2349.69518249437|\n",
            "|AK_ALEUTIANS_EAST|5184140| 6711.0310331696|\n",
            "|AK_ALEUTIANS_EAST|5184141|6733.95986371512|\n",
            "+-----------------+-------+----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "CSSF data available for 12825 region(s)\n",
            "CSSF data\n",
            "+-------+-----+-----+---------+-------+----+\n",
            "|GRID_ID|FYEAR|DEKAD|      DVS|   TAGP|TWSO|\n",
            "+-------+-----+-----+---------+-------+----+\n",
            "|4338827| 2000|    5|0.0312374|99.4868| 0.0|\n",
            "|4338827| 2000|    6|0.0977538| 457.04| 0.0|\n",
            "|4338827| 2000|    7| 0.181396|1004.21| 0.0|\n",
            "|4338827| 2000|    8| 0.242021|1604.66| 0.0|\n",
            "|4338827| 2000|    9| 0.349639|2592.59| 0.0|\n",
            "|4338827| 2000|   10| 0.425815|3779.37| 0.0|\n",
            "|4338827| 2000|   11| 0.525692|5027.69| 0.0|\n",
            "|4338827| 2000|   12| 0.638996|6619.58| 0.0|\n",
            "|4338827| 2000|   13| 0.758808|7855.06| 0.0|\n",
            "|4338827| 2000|   14| 0.888689|9333.19| 0.0|\n",
            "+-------+-----+-----+---------+-------+----+\n",
            "only showing top 10 rows\n",
            "\n",
            "METEO data available for 58502 region(s)\n",
            "METEO data\n",
            "+-------+-----+-----+----+----+--------+--------+-------+----+-----+--------+------+\n",
            "|GRID_ID|FYEAR|DEKAD|TMAX|TMIN|    TAVG|   VPRES|   WSPD|PREC|  ET0|     RAD|   CWB|\n",
            "+-------+-----+-----+----+----+--------+--------+-------+----+-----+--------+------+\n",
            "|4320700| 2000|    1|20.7|-0.4|    7.61|   4.488|   2.35| 0.0|23.41|152665.0|-23.41|\n",
            "|4320700| 2000|    2|26.8| 1.5|   13.11|   5.824|   1.91| 0.0|29.06|158253.0|-29.06|\n",
            "|4320700| 2000|    3|25.4| 1.8|12.00909|6.578182|1.93636| 0.0|29.91|181556.0|-29.91|\n",
            "|4320700| 2000|    4|25.5| 2.1|   12.08|   5.464|   2.34| 0.0|33.26|181207.0|-33.26|\n",
            "|4320700| 2000|    5|25.7| 3.1|   13.16|   6.789|   2.37| 0.0|34.47|191289.0|-34.47|\n",
            "|4320700| 2000|    6|25.5| 2.6|11.44444|6.456667|2.85556| 4.0|32.62|184468.0|-28.62|\n",
            "|4320700| 2000|    7|22.9| 0.6|   10.96|   7.052|   3.01|24.3|35.73|215608.0|-11.43|\n",
            "|4320700| 2000|    8|25.1| 4.8|   14.47|   7.536|   2.68| 1.2|44.62|238365.0|-43.42|\n",
            "|4320700| 2000|    9|26.3| 1.2|13.28182|6.573636|2.57273| 1.8|49.11|275452.0|-47.31|\n",
            "|4320700| 2000|   10|30.7| 5.0|   16.81|   7.092|   2.56| 0.0|52.93|261830.0|-52.93|\n",
            "+-------+-----+-----+----+----+--------+--------+-------+----+-----+--------+------+\n",
            "only showing top 10 rows\n",
            "\n",
            "REMOTE_SENSING data available for 12963 region(s)\n",
            "REMOTE_SENSING data\n",
            "+-------+-----+-----+-------------------+\n",
            "|GRID_ID|FYEAR|DEKAD|              FAPAR|\n",
            "+-------+-----+-----+-------------------+\n",
            "|4338827| 2000|    1|0.17125000059604645|\n",
            "|4338827| 2000|    2|0.15691667795181274|\n",
            "|4338827| 2000|    3|0.16858333349227905|\n",
            "|4338827| 2000|    4|0.18524999916553497|\n",
            "|4338827| 2000|    5|0.25966668128967285|\n",
            "|4338827| 2000|    6| 0.3643333613872528|\n",
            "|4338827| 2000|    7|0.40658333897590637|\n",
            "|4338827| 2000|    8|0.44341668486595154|\n",
            "|4338827| 2000|    9| 0.5211666822433472|\n",
            "|4338827| 2000|   10| 0.5551667213439941|\n",
            "+-------+-----+-----+-------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "CROP_AREA data available for 2215 region(s)\n",
            "CROP_AREA data\n",
            "+----------+-----+---------+----------+\n",
            "| COUNTY_ID|FYEAR|CROP_AREA|TOTAL_AREA|\n",
            "+----------+-----+---------+----------+\n",
            "|AL_AUTAUGA| 1999|     1600| 380443.97|\n",
            "|AL_AUTAUGA| 2000|     1300| 380443.97|\n",
            "|AL_AUTAUGA| 2001|     1200| 380443.97|\n",
            "|AL_AUTAUGA| 2002|     2000| 380443.97|\n",
            "|AL_AUTAUGA| 2003|     2400| 380443.97|\n",
            "|AL_AUTAUGA| 2004|     1700| 380443.97|\n",
            "|AL_AUTAUGA| 2005|     2300| 380443.97|\n",
            "|AL_AUTAUGA| 2006|     2500| 380443.97|\n",
            "|AL_AUTAUGA| 2007|     1500| 380443.97|\n",
            "|AL_AUTAUGA| 2011|     1040| 380443.97|\n",
            "+----------+-----+---------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "YIELD data available for 2403 region(s)\n",
            "YIELD data\n",
            "+----------+-----+-----+\n",
            "| COUNTY_ID|FYEAR|YIELD|\n",
            "+----------+-----+-----+\n",
            "|AL_AUTAUGA| 1994| 5.38|\n",
            "|AL_AUTAUGA| 1995|3.363|\n",
            "|AL_AUTAUGA| 1996|2.556|\n",
            "|AL_AUTAUGA| 1997|5.044|\n",
            "|AL_AUTAUGA| 1998|2.219|\n",
            "|AL_AUTAUGA| 1999|5.111|\n",
            "|AL_AUTAUGA| 2000|2.085|\n",
            "|AL_AUTAUGA| 2001|4.775|\n",
            "|AL_AUTAUGA| 2002|3.497|\n",
            "|AL_AUTAUGA| 2003| 8.07|\n",
            "+----------+-----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def loadAndPreprocessData(cyp_config, data_sources,\n",
        "                          dekadal_data_sources, static_data_sources):\n",
        "  \"\"\"Load, preprocess and combine data sources\"\"\"\n",
        "  crop = cyp_config['crop']\n",
        "  season_crosses = cyp_config['season_crosses_calendar_year']\n",
        "  country = cyp_config['country_code']\n",
        "  data_path = cyp_config['data_path']\n",
        "  early_season_end = cyp_config['early_season_end_dekad']\n",
        "  high_res_id_col = cyp_config['high_res_id_col']\n",
        "  low_res_id_col = cyp_config['low_res_id_col']\n",
        "  print_debug = (cyp_config['debug_level'] > 1)\n",
        "\n",
        "  data_dfs = loadAllData(spark, data_sources, data_path=data_path, country=country)\n",
        "  data_dfs = preprocessData(spark, data_dfs, data_sources,\n",
        "                            crop, season_crosses_calyear=season_crosses,\n",
        "                            print_debug=print_debug)\n",
        "\n",
        "  combined_dfs, country_years = combineInputData(data_sources, data_dfs,\n",
        "                                                 dekadal_data_sources,\n",
        "                                                 static_data_sources,\n",
        "                                                 high_res_id_col, low_res_id_col,\n",
        "                                                 early_season_end=early_season_end,\n",
        "                                                 print_debug=print_debug)\n",
        "\n",
        "  return combined_dfs, country_years\n",
        "\n",
        "if (test_env == 'guanabana'):\n",
        "  crop = cyp_config['crop']\n",
        "  input_spatial_level = cyp_config['input_spatial_level']\n",
        "  label_spatial_level = cyp_config['label_spatial_level']\n",
        "  input_order_cols = ['GRID_ID', 'FYEAR', 'DEKAD']\n",
        "  label_order_cols = ['COUNTY_ID', 'FYEAR']\n",
        "  cssf_indicators = ['TAGP', 'TWSO']\n",
        "  meteo_indicators = ['TMAX', 'TMIN', 'TAVG', 'PREC', 'CWB']\n",
        "  rs_indicators = [ 'FAPAR' ]\n",
        "\n",
        "  data_sources = {\n",
        "      'COUNTY' : {\n",
        "          'spatial_level' : input_spatial_level,\n",
        "          'order_cols' : ['COUNTY_ID', 'GRID_ID'],\n",
        "          'sel_cols' : ['COUNTY_ID', 'GRID_ID', 'TOTAL_AREA']\n",
        "      },\n",
        "      'CSSF' : { 'spatial_level' : input_spatial_level,\n",
        "                 'order_cols' : input_order_cols,\n",
        "                 'sel_cols' : input_order_cols + cssf_indicators\n",
        "      },\n",
        "      'METEO' : { 'spatial_level' : input_spatial_level,\n",
        "                  'order_cols' : input_order_cols,\n",
        "                  'sel_cols' : input_order_cols + meteo_indicators\n",
        "      },\n",
        "      'REMOTE_SENSING' : { 'spatial_level' : input_spatial_level,\n",
        "                           'order_cols' : input_order_cols,\n",
        "                           'sel_cols' : input_order_cols + rs_indicators\n",
        "      },\n",
        "      'SOIL' : { 'spatial_level' : input_spatial_level,\n",
        "                 'order_cols' : ['GRID_ID'],\n",
        "                 'sel_cols' : [ 'GRID_ID', 'SM_WHC' ]\n",
        "      },\n",
        "      'CROP_AREA' : { 'spatial_level' : label_spatial_level,\n",
        "                      'order_cols' : label_order_cols,\n",
        "                      'sel_cols' : label_order_cols + ['CROP_AREA']\n",
        "      },\n",
        "      'YIELD' : { 'spatial_level' : label_spatial_level,\n",
        "                  'order_cols' : label_order_cols,\n",
        "                  'sel_cols' : label_order_cols + [ 'YIELD' ]\n",
        "      },\n",
        "  }\n",
        "\n",
        "  dekadal_data_sources = ['CSSF', 'METEO', 'REMOTE_SENSING']\n",
        "  static_data_sources = ['SOIL']\n",
        "  combined_dfs, country_years = loadAndPreprocessData(cyp_config, data_sources,\n",
        "                                                      dekadal_data_sources, static_data_sources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLJeBWYEo6nj"
      },
      "source": [
        "### Optimize Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhciRFtQo-a_"
      },
      "source": [
        "#### CV Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExkDqqwApAp6",
        "outputId": "885791f1-dc0a-4a79-ff9f-82166177cd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----------------\n",
            "Training data\n",
            "----------------\n",
            "\n",
            "\n",
            "Dekadal features: TAGP, TWSO, TMAX, TMIN, TAVG, PREC, CWB, FAPAR\n",
            "Trend features: YIELD-5, YIELD-4, YIELD-3, YIELD-2, YIELD-1\n",
            "Label columns: YIELD\n",
            "\n",
            " Training years: 2000, 2001, 2002, 2003, 2004, 2005, 2006\n",
            "\n",
            "\n",
            "Label data: 11097, 4\n",
            "\n",
            "------------------\n",
            "Validation data\n",
            "------------------\n",
            "\n",
            "\n",
            "Dekadal features: TAGP, TWSO, TMAX, TMIN, TAVG, PREC, CWB, FAPAR\n",
            "Trend features: YIELD-5, YIELD-4, YIELD-3, YIELD-2, YIELD-1\n",
            "Label columns: YIELD\n",
            "\n",
            " Validation years: 2007, 2008, 2009, 2010, 2011\n",
            "\n",
            "\n",
            "Label data: 6879, 4\n"
          ]
        }
      ],
      "source": [
        "def getCustomCVDatasets(cyp_config, combined_dfs, log_fh):\n",
        "  \"\"\"Get training and validation datasets for custom cv\"\"\"\n",
        "  num_folds = cyp_config['num_cv_folds']\n",
        "  num_valid_years = cyp_config['num_valid_years']\n",
        "  test_fraction = cyp_config['test_fraction']\n",
        "  use_yield_trend = cyp_config['use_yield_trend']\n",
        "  early_season_end = cyp_config['early_season_end_dekad']\n",
        "\n",
        "  cv_datasets = []\n",
        "  for fold_iter in range(num_folds):\n",
        "    scaler_args = {}\n",
        "    train_dataset = CYPMLDataset(combined_dfs, country_years,\n",
        "                                 yield_trend=use_yield_trend,\n",
        "                                 early_season_end=early_season_end,\n",
        "                                 is_train=True, test_fraction=test_fraction,\n",
        "                                 num_folds = num_folds, num_valid_years=num_valid_years,\n",
        "                                 fold_iter=fold_iter,\n",
        "                                 scaler_args=scaler_args,\n",
        "                                 print_debug=(fold_iter == 0),\n",
        "                                 log_fh=log_fh)\n",
        "\n",
        "    valid_dataset = CYPMLDataset(combined_dfs, country_years,\n",
        "                                 yield_trend=use_yield_trend,\n",
        "                                 early_season_end=early_season_end,\n",
        "                                 is_train=False, is_validation=True,\n",
        "                                 test_fraction=test_fraction,\n",
        "                                 num_folds = num_folds, num_valid_years=num_valid_years,\n",
        "                                 fold_iter=fold_iter,\n",
        "                                 scaler_args=scaler_args,\n",
        "                                 print_debug=(fold_iter == 0),\n",
        "                                 log_fh=log_fh)\n",
        "\n",
        "    cv_datasets.append([train_dataset, valid_dataset])\n",
        "\n",
        "  return cv_datasets\n",
        "\n",
        "if (test_env == 'guanabana'):\n",
        "  cv_datasets = getCustomCVDatasets(cyp_config, combined_dfs, log_fh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32i4FZVb1Odt"
      },
      "source": [
        "#### Hyperparameter Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftz7-jbmjqai",
        "outputId": "baee5ab2-281c-4c88-9664-20a914b768b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CYPLSTMModel(\n",
            "  (ts_rnns): ModuleList()\n",
            "  (rnn): LSTM(8, 64, batch_first=True)\n",
            "  (fc): Linear(in_features=69, out_features=2, bias=True)\n",
            ")\n",
            "\n",
            "Searching for optimal hyperparameters ...\n",
            "-------------------------------------------\n",
            "torch.Size([26, 64]) torch.Size([26, 2]) torch.Size([26, 5])\n",
            "torch.Size([26, 64]) torch.Size([26, 2]) torch.Size([26, 5])\n",
            "torch.Size([26, 64]) torch.Size([26, 2]) torch.Size([26, 5])\n",
            "torch.Size([26, 64]) torch.Size([26, 2]) torch.Size([26, 5])\n",
            "torch.Size([26, 64]) torch.Size([26, 2]) torch.Size([26, 5])\n",
            "torch.Size([26, 64]) torch.Size([26, 2]) torch.Size([26, 5])\n",
            "torch.Size([26, 64]) torch.Size([26, 2]) torch.Size([26, 5])\n",
            "torch.Size([64, 64]) torch.Size([64, 2]) torch.Size([64, 5])\n",
            "torch.Size([64, 64]) torch.Size([64, 2]) torch.Size([64, 5])\n",
            "torch.Size([64, 64]) torch.Size([64, 2]) torch.Size([64, 5])\n",
            "torch.Size([64, 64]) torch.Size([64, 2]) torch.Size([64, 5])\n",
            "torch.Size([64, 64]) torch.Size([64, 2]) torch.Size([64, 5])\n",
            "torch.Size([64, 64]) torch.Size([64, 2]) torch.Size([64, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([34, 64]) torch.Size([34, 2]) torch.Size([34, 5])\n",
            "torch.Size([27, 64]) torch.Size([27, 2]) torch.Size([27, 5])\n",
            "torch.Size([27, 64]) torch.Size([27, 2]) torch.Size([27, 5])\n",
            "torch.Size([27, 64]) torch.Size([27, 2]) torch.Size([27, 5])\n",
            "torch.Size([27, 64]) torch.Size([27, 2]) torch.Size([27, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([24, 64]) torch.Size([24, 2]) torch.Size([24, 5])\n",
            "torch.Size([24, 64]) torch.Size([24, 2]) torch.Size([24, 5])\n",
            "torch.Size([24, 64]) torch.Size([24, 2]) torch.Size([24, 5])\n",
            "torch.Size([24, 64]) torch.Size([24, 2]) torch.Size([24, 5])\n",
            "torch.Size([24, 64]) torch.Size([24, 2]) torch.Size([24, 5])\n",
            "torch.Size([24, 64]) torch.Size([24, 2]) torch.Size([24, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([25, 64]) torch.Size([25, 2]) torch.Size([25, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([31, 64]) torch.Size([31, 2]) torch.Size([31, 5])\n",
            "torch.Size([35, 64]) torch.Size([35, 2]) torch.Size([35, 5])\n",
            "torch.Size([35, 64]) torch.Size([35, 2]) torch.Size([35, 5])\n",
            "torch.Size([35, 64]) torch.Size([35, 2]) torch.Size([35, 5])\n",
            "torch.Size([35, 64]) torch.Size([35, 2]) torch.Size([35, 5])\n",
            "torch.Size([35, 64]) torch.Size([35, 2]) torch.Size([35, 5])\n",
            "torch.Size([35, 64]) torch.Size([35, 2]) torch.Size([35, 5])\n"
          ]
        }
      ],
      "source": [
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "def optimizeHyperparameters(cyp_config, cv_datasets, log_fh):\n",
        "  loss = nn.MSELoss()\n",
        "  # consider using Huber Loss\n",
        "  # loss = nn.HuberLoss(reduction='mean', delta=1.35)\n",
        "\n",
        "  num_folds = cyp_config['num_cv_folds']\n",
        "  debug_level = cyp_config['debug_level']\n",
        "  architecture = cyp_config['architecture']\n",
        "  best_cv_nrmse = None\n",
        "  # optimize?\n",
        "  num_epochs = 100\n",
        "\n",
        "  loss_weight_space = [0.5] #, 0.6]\n",
        "  lr_space = [1e-3, 5e-4]\n",
        "  weight_decay_space = [1e-4, 1e-5]\n",
        "  best_loss_weight = loss_weight_space[0]\n",
        "  best_lr = lr_space[0]\n",
        "  best_lambda = weight_decay_space[0]\n",
        "\n",
        "  custom_cv_params = {}\n",
        "  row_idx = 0\n",
        "  for loss_weight in loss_weight_space:\n",
        "    for lr in lr_space:\n",
        "      for weight_decay in weight_decay_space:\n",
        "        cv_nrmses = []\n",
        "        for fold_iter in range(num_folds):\n",
        "          train_dataset = cv_datasets[fold_iter][0]\n",
        "          valid_dataset = cv_datasets[fold_iter][1]\n",
        "          train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1,\n",
        "                                                     shuffle=True, num_workers=4)\n",
        "          valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1,\n",
        "                                                     shuffle=False, num_workers=4)\n",
        "\n",
        "          # train_dataset is : X_ts, X_rest, X_trend.\n",
        "          # X_rest shape is (num_regions, variables). Skip TOTAL_AREA\n",
        "          train_data_item = train_dataset[0]\n",
        "          num_other_features = train_data_item[1].shape[1] - 1\n",
        "\n",
        "          # X_trend shape is (trend_window)\n",
        "          num_trend_features = train_data_item[2].shape[0]\n",
        "\n",
        "          # time series (dekadal) data is [num_regions, num_dekads, num_indicators]\n",
        "          num_ts_indicators = train_data_item[0].shape[2]\n",
        "          ts_seq_len = train_data_item[0].shape[1]\n",
        "\n",
        "          device = d2l.try_gpu()\n",
        "          net = CYPLSTMModel(num_ts_indicators,\n",
        "                             num_trend_features,\n",
        "                             num_other_features,\n",
        "                             ts_seq_len=ts_seq_len,\n",
        "                             num_outputs=2)\n",
        "\n",
        "          if ((debug_level > 1) and (row_idx == 0) and (fold_iter == 0)):\n",
        "            print(net)\n",
        "            print('\\nSearching for optimal hyperparameters ...' )\n",
        "            print('-------------------------------------------' )\n",
        "\n",
        "          net = net.to(device)\n",
        "          # need to handle 64 bit values\n",
        "          net.double()\n",
        "          trainer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "          val_nrmse, _ = train(net, train_dataset, train_loader, valid_loader, loss, loss_weight,\n",
        "                               trainer, num_epochs, early_stopping=True, device=device)\n",
        "          cv_nrmses.append(val_nrmse)\n",
        "\n",
        "        avg_cv_nrmse = round(np.mean(cv_nrmses), 4)\n",
        "        std_cv_nrmse = round(np.std(cv_nrmses), 4)\n",
        "        if (debug_level > 1):\n",
        "          print(\"yield loss weight:\", loss_weight, \", lr:\", lr, \", weight decay:\", weight_decay,\n",
        "                \", avg cv NRMSE:\", avg_cv_nrmse, \", std cv NRMSE:\", std_cv_nrmse)\n",
        "\n",
        "        cv_row = [loss_weight, lr, weight_decay,  avg_cv_nrmse, std_cv_nrmse]\n",
        "        custom_cv_params['row' + str(row_idx)] = cv_row\n",
        "        row_idx += 1\n",
        "\n",
        "        if ((best_cv_nrmse is None) or (avg_cv_nrmse < best_cv_nrmse)):\n",
        "          best_cv_nrmse = avg_cv_nrmse\n",
        "          best_loss_weight = loss_weight\n",
        "          best_lr = lr\n",
        "          best_lambda = weight_decay\n",
        "\n",
        "  cv_params = ['Yield Loss Weight', 'Learning Rate', 'Weight Decay', 'Avg CV NRMSE', 'STD CV NRMSE']\n",
        "  pd_cv_params_df = pd.DataFrame.from_dict(custom_cv_params, orient='index',\n",
        "                                          columns=cv_params)\n",
        "\n",
        "  cv_info = '\\n' + pd_cv_params_df.head(row_idx).to_string(index=False)\n",
        "  cv_info += \"\\nOptimal yield loss weight: \" + str(best_loss_weight)\n",
        "  cv_info += \"\\nOptimal lr: \" + str(best_lr)\n",
        "  cv_info += \"\\nOptimal weight decay lambda: \" + str(best_lambda)\n",
        "\n",
        "  log_fh.write(cv_info)\n",
        "  if (debug_level > 1):\n",
        "    print(cv_info)\n",
        "\n",
        "  best_params = {\n",
        "      'loss_split' : best_loss_weight,\n",
        "      'lr' : best_lr,\n",
        "      'weight_decay' : best_lambda\n",
        "  }\n",
        "\n",
        "  return best_params\n",
        "\n",
        "if (test_env == 'guanabana'):\n",
        "  best_params = optimizeHyperparameters(cyp_config, cv_datasets, log_fh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StPq7GJr2z0e"
      },
      "source": [
        "### Refit using Optimal Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoisXzMJ22TG"
      },
      "outputs": [],
      "source": [
        "# best_params = {\n",
        "#     'loss_split' : 0.5,\n",
        "#     'lr' : 0.0005,\n",
        "#     'weight_decay' : 0.0001\n",
        "# }\n",
        "\n",
        "def evaluateOptimalHyperparameters(cyp_config,\n",
        "                                   combined_dfs,\n",
        "                                   country_years,\n",
        "                                   best_params,\n",
        "                                   is_validation=False,\n",
        "                                   early_stopping=False,\n",
        "                                   visualize=False, country=None):\n",
        "  \"\"\"\n",
        "  1. Evaluate on validation data: num_valid_years = 5\n",
        "  2. Evaluate on test data: num_valid_years = 0.\n",
        "  \"\"\"\n",
        "  loss = nn.MSELoss()\n",
        "  num_epochs = best_params['num_epochs']\n",
        "  architecture = cyp_config['architecture']\n",
        "\n",
        "  test_fraction = cyp_config['test_fraction']\n",
        "  use_yield_trend = cyp_config['use_yield_trend']\n",
        "  early_season_end = cyp_config['early_season_end_dekad']\n",
        "  print_debug = cyp_config['debug_level'] > 1\n",
        "  num_valid_years = 5 if (is_validation) else 0\n",
        "\n",
        "  scaler_args = {}\n",
        "  train_dataset = CYPMLDataset(combined_dfs, country_years,\n",
        "                               yield_trend=use_yield_trend,\n",
        "                               early_season_end=early_season_end,\n",
        "                               is_train=True,\n",
        "                               test_fraction=test_fraction,\n",
        "                               num_folds=1, fold_iter=0,\n",
        "                               num_valid_years=num_valid_years,\n",
        "                               scaler_args=scaler_args,\n",
        "                               print_debug=print_debug,\n",
        "                               log_fh=log_fh)\n",
        "\n",
        "  test_dataset = CYPMLDataset(combined_dfs, country_years,\n",
        "                              early_season_end=early_season_end,\n",
        "                              is_train=False, is_validation=is_validation,\n",
        "                              test_fraction=test_fraction,\n",
        "                              num_folds=1, fold_iter=0,\n",
        "                              num_valid_years=num_valid_years,\n",
        "                              scaler_args=scaler_args,\n",
        "                              print_debug=print_debug,\n",
        "                              log_fh=log_fh)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
        "                                            shuffle=False, num_workers=4)\n",
        "\n",
        "  y_max = 1.0 # torch.max(train_dataset[0][3]).item()/2\n",
        "  # train_dataset is : X_ts, X_rest, X_trend.\n",
        "  # X_rest shape is (num_regions, variables). Skip TOTAL_AREA\n",
        "  train_data_item = train_dataset[0]\n",
        "  num_other_features = train_data_item[1].shape[1] - 1\n",
        "\n",
        "  # X_trend shape is (trend_window)\n",
        "  num_trend_features = train_data_item[2].shape[0]\n",
        "\n",
        "  # time series (dekadal) data is [num_regions, num_dekads, num_indicators]\n",
        "  num_ts_indicators = train_data_item[0].shape[2]\n",
        "  ts_seq_len = train_data_item[0].shape[1]\n",
        "\n",
        "  device = d2l.try_gpu()\n",
        "  net = CYPLSTMModel(num_ts_indicators,\n",
        "                     num_trend_features,\n",
        "                     num_other_features,\n",
        "                     ts_seq_len=ts_seq_len,\n",
        "                     num_outputs=2)\n",
        "\n",
        "  net = net.to(device)\n",
        "  # need to handle 64 bit values\n",
        "  net.double()\n",
        "  trainer = torch.optim.Adam(net.parameters(), lr=best_params['lr'],\n",
        "                             weight_decay=best_params['weight_decay'])\n",
        "\n",
        "  test_nrmse, epochs_run = train(net, train_dataset, train_loader, test_loader,\n",
        "                                 loss, best_params['loss_split'],\n",
        "                                 trainer, num_epochs,\n",
        "                                 early_stopping=early_stopping, device=device,\n",
        "                                 country=country, visualize=visualize, ymax=y_max)\n",
        "\n",
        "  if (early_stopping):\n",
        "    best_params['num_epochs'] = epochs_run\n",
        "\n",
        "  print('NRMSE:', round(test_nrmse, 4))\n",
        "  preds_l, preds_h, test_nrmse = evaluatePredictions(net, test_loader, device)\n",
        "\n",
        "  return net, preds_l, preds_h, test_nrmse\n",
        "\n",
        "if (test_env == 'guanabana'):\n",
        "  yield_grids_file = 'YIELD_GRIDS_US.csv'\n",
        "  data_path = cyp_config['data_path']\n",
        "  grids_yield_df = spark.read.csv(data_path + '/' + yield_grids_file,\n",
        "                                  header=True, inferSchema=True)\n",
        "  pd_grids_yield_df = grids_yield_df.toPandas()\n",
        "  pd_grids_yield_df = pd_grids_yield_df.dropna(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW2dzOr98vu-"
      },
      "source": [
        "### Evaluate on validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "otD0vpdI8zW3",
        "outputId": "034f10d5-552b-4419-cc6a-5d585b1214bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NRMSE: 0.1315\n",
            "Validation NRMSE: 13.15\n",
            "\n",
            " soft wheat DE\n",
            "Level y NRMSE: 12.198202192557686\n",
            "  COUNTRY NUTS2_ID   FYEAR  YIELD  YIELD_PRED  CROP_AREA  CROP_AREA_PRED\n",
            "0      DE     DE11  2008.0   7.32    7.320339    94465.0    78442.578125\n",
            "1      DE     DE11  2009.0   7.46    7.535677    96197.0    75816.406250\n",
            "2      DE     DE11  2010.0   6.86    7.406305    99324.0    79379.062500\n",
            "3      DE     DE11  2011.0   6.75    7.463986    94730.0    72258.320312\n",
            "4      DE     DE11  2012.0   6.24    7.292805    82819.0    72554.796875\n",
            "5      DE     DE12  2008.0   6.97    6.537163    41153.0    43119.347656\n",
            "6      DE     DE12  2009.0   6.90    6.764137    41907.0    42440.816406\n",
            "7      DE     DE12  2010.0   6.38    6.708055    42844.0    45343.445312\n",
            "8      DE     DE12  2011.0   6.17    6.735574    41267.0    40398.441406\n",
            "9      DE     DE12  2012.0   6.12    6.645390    36079.0    41434.285156\n",
            "\n",
            "Level x NRMSE: 19.29601565579957\n",
            "   id_x   FYEAR  YIELD_PRED COUNTRY NUTS3_ID NUTS2_ID  id_y  id0  YIELD\n",
            "0   0.0  2008.0    7.440061      DE    DE118     DE11     0    0   7.86\n",
            "1   0.0  2009.0    7.596873      DE    DE118     DE11     0    0   7.81\n",
            "2   0.0  2010.0    7.417739      DE    DE118     DE11     0    0   7.35\n",
            "3   0.0  2011.0    7.545953      DE    DE118     DE11     0    0   7.19\n",
            "4   0.0  2012.0    7.427184      DE    DE118     DE11     0    0   6.71\n",
            "5   1.0  2008.0    7.393690      DE    DE119     DE11     0    0   7.37\n",
            "6   1.0  2009.0    7.538008      DE    DE119     DE11     0    0   8.05\n",
            "7   1.0  2010.0    7.436659      DE    DE119     DE11     0    0   6.92\n",
            "8   1.0  2011.0    7.430521      DE    DE119     DE11     0    0   6.07\n",
            "9   1.0  2012.0    7.369081      DE    DE119     DE11     0    0   5.76\n",
            "\n",
            " soft wheat ES\n",
            "Level y NRMSE: 21.470528742532625\n",
            "    COUNTRY NUTS2_ID   FYEAR  YIELD  YIELD_PRED  CROP_AREA  CROP_AREA_PRED\n",
            "150      ES     ES13  2007.0   2.67    2.976099      462.0    15869.889648\n",
            "151      ES     ES13  2008.0   2.56    2.931009      935.0    17486.492188\n",
            "152      ES     ES13  2009.0   2.44    2.804278      346.0    14872.455078\n",
            "153      ES     ES13  2010.0   2.45    2.592606      462.0    13664.234375\n",
            "154      ES     ES13  2011.0   2.46    2.613974      560.0    13684.761719\n",
            "155      ES     ES21  2007.0   5.00    5.127838    24714.0    15947.139648\n",
            "156      ES     ES21  2008.0   4.60    5.053288    26580.0    17133.406250\n",
            "157      ES     ES21  2009.0   4.80    4.860668    15352.0    15371.115234\n",
            "158      ES     ES21  2010.0   5.94    4.772847    26040.0    15001.145508\n",
            "159      ES     ES21  2011.0   6.19    5.018284    25137.0    16336.509766\n",
            "\n",
            "Level x NRMSE: 26.309958497960018\n",
            "      id_x   FYEAR  YIELD_PRED COUNTRY NUTS3_ID NUTS2_ID  id_y  id0  YIELD\n",
            "709  154.0  2007.0    2.976099      ES    ES130     ES13    36    1   2.67\n",
            "710  154.0  2008.0    2.931009      ES    ES130     ES13    36    1   2.56\n",
            "711  154.0  2009.0    2.804278      ES    ES130     ES13    36    1   2.44\n",
            "712  154.0  2010.0    2.592606      ES    ES130     ES13    36    1   2.45\n",
            "713  154.0  2011.0    2.613974      ES    ES130     ES13    36    1   2.46\n",
            "714  155.0  2007.0    5.127838      ES    ES211     ES21    37    1   5.00\n",
            "715  155.0  2008.0    5.053288      ES    ES211     ES21    37    1   4.60\n",
            "716  155.0  2009.0    4.860668      ES    ES211     ES21    37    1   4.80\n",
            "717  155.0  2010.0    4.772847      ES    ES211     ES21    37    1   5.95\n",
            "718  155.0  2011.0    5.018284      ES    ES211     ES21    37    1   6.20\n",
            "\n",
            " soft wheat FR\n",
            "Level y NRMSE: 9.710887092410184\n",
            "    COUNTRY NUTS2_ID   FYEAR  YIELD  YIELD_PRED  CROP_AREA  CROP_AREA_PRED\n",
            "215      FR     FR10  2006.0   7.39    7.347847   242580.0   220886.781250\n",
            "216      FR     FR10  2007.0   7.72    7.334534   239091.0   186885.015625\n",
            "217      FR     FR10  2008.0   8.22    7.305933   242049.0   206304.171875\n",
            "218      FR     FR10  2009.0   8.74    7.543192   234548.0   207116.187500\n",
            "219      FR     FR10  2010.0   8.11    7.442327   230658.0   211656.468750\n",
            "220      FR     FRB0  2006.0   6.52    6.910471   688784.0   741036.625000\n",
            "221      FR     FRB0  2007.0   6.43    6.889945   691087.0   634799.062500\n",
            "222      FR     FRB0  2008.0   6.95    6.767327   710295.0   683890.250000\n",
            "223      FR     FRB0  2009.0   7.27    6.913340   665074.0   681565.500000\n",
            "224      FR     FRB0  2010.0   6.86    6.781939   667350.0   691829.812500\n",
            "\n",
            "Level x NRMSE: 14.098289147146103\n",
            "      id_x   FYEAR  YIELD_PRED COUNTRY NUTS3_ID NUTS2_ID  id_y  id0  YIELD\n",
            "909  194.0  2006.0    7.290077      FR    FR102     FR10    50    2    7.6\n",
            "910  194.0  2007.0    7.312201      FR    FR102     FR10    50    2    7.8\n",
            "911  194.0  2008.0    7.269923      FR    FR102     FR10    50    2    8.2\n",
            "912  194.0  2009.0    7.555922      FR    FR102     FR10    50    2    8.9\n",
            "913  194.0  2010.0    7.457607      FR    FR102     FR10    50    2    8.3\n",
            "914  195.0  2006.0    7.522321      FR    FR103     FR10    50    2    7.2\n",
            "915  195.0  2007.0    7.420993      FR    FR103     FR10    50    2    7.6\n",
            "916  195.0  2008.0    7.410467      FR    FR103     FR10    50    2    8.2\n",
            "917  195.0  2009.0    7.624717      FR    FR103     FR10    50    2    8.4\n",
            "918  195.0  2010.0    7.534019      FR    FR103     FR10    50    2    7.6\n",
            "\n",
            " soft wheat IT\n",
            "Level y NRMSE: 17.474684181719976\n",
            "    COUNTRY NUTS2_ID   FYEAR  YIELD  YIELD_PRED  CROP_AREA  CROP_AREA_PRED\n",
            "320      IT     ITC1  2007.0   5.13    4.676317    94458.0    78917.156250\n",
            "321      IT     ITC1  2008.0   4.55    4.730375   102711.0    84664.546875\n",
            "322      IT     ITC1  2009.0   4.50    4.759752    92105.0    76875.187500\n",
            "323      IT     ITC1  2010.0   5.29    4.687652    86515.0    80726.312500\n",
            "324      IT     ITC1  2011.0   4.81    4.705215    91073.0    72378.125000\n",
            "325      IT     ITC4  2007.0   5.27    5.625450    73672.0    55903.273438\n",
            "326      IT     ITC4  2008.0   6.02    5.565635    80908.0    57389.914062\n",
            "327      IT     ITC4  2009.0   5.58    5.544188    65715.0    55169.640625\n",
            "328      IT     ITC4  2010.0   5.84    5.678016    58015.0    62834.093750\n",
            "329      IT     ITC4  2011.0   5.08    5.421553    45050.0    50643.601562\n",
            "\n",
            "Level x NRMSE: 20.9975931941074\n",
            "       id_x   FYEAR  YIELD_PRED COUNTRY NUTS3_ID NUTS2_ID  id_y  id0  YIELD\n",
            "1349  282.0  2007.0    4.775181      IT    ITC11     ITC1    72    3   6.20\n",
            "1350  282.0  2008.0    4.844927      IT    ITC11     ITC1    72    3   5.20\n",
            "1351  282.0  2009.0    4.863161      IT    ITC11     ITC1    72    3   4.96\n",
            "1352  282.0  2010.0    4.663237      IT    ITC11     ITC1    72    3   5.23\n",
            "1353  282.0  2011.0    4.762222      IT    ITC11     ITC1    72    3   5.30\n",
            "1354  283.0  2007.0    4.991877      IT    ITC12     ITC1    72    3   5.10\n",
            "1355  283.0  2008.0    4.805424      IT    ITC12     ITC1    72    3   5.11\n",
            "1356  283.0  2009.0    4.837895      IT    ITC12     ITC1    72    3   5.09\n",
            "1357  283.0  2010.0    4.925795      IT    ITC12     ITC1    72    3   5.13\n",
            "1358  283.0  2011.0    4.971617      IT    ITC12     ITC1    72    3   5.06\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"320.355469pt\" version=\"1.1\" viewBox=\"0 0 339.525 320.355469\" width=\"339.525pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 320.355469 \nL 339.525 320.355469 \nL 339.525 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 282.799219 \nL 322.78125 282.799219 \nL 322.78125 10.999219 \nL 43.78125 10.999219 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 97.326705 282.799219 \nL 97.326705 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m6b80cc9d6b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.326705\" xlink:href=\"#m6b80cc9d6b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(90.964205 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 153.690341 282.799219 \nL 153.690341 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"153.690341\" xlink:href=\"#m6b80cc9d6b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(147.327841 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 210.053977 282.799219 \nL 210.053977 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"210.053977\" xlink:href=\"#m6b80cc9d6b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(203.691477 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 266.417614 282.799219 \nL 266.417614 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"266.417614\" xlink:href=\"#m6b80cc9d6b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 80 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(260.055114 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 322.78125 282.799219 \nL 322.78125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"322.78125\" xlink:href=\"#m6b80cc9d6b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(313.2375 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- epoch -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(168.053125 311.075781)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 282.799219 \nL 322.78125 282.799219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m755a30470a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m755a30470a\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(20.878125 286.598437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 228.439219 \nL 322.78125 228.439219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m755a30470a\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 232.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 174.079219 \nL 322.78125 174.079219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m755a30470a\" y=\"174.079219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 177.878437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 119.719219 \nL 322.78125 119.719219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m755a30470a\" y=\"119.719219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 123.518437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 65.359219 \nL 322.78125 65.359219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m755a30470a\" y=\"65.359219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 69.158437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 10.999219 \nL 322.78125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m755a30470a\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 14.798438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- loss -->\n     <defs>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(14.798438 156.557031)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 202.758975 \nL 46.599432 251.42577 \nL 49.417614 254.832838 \nL 52.235795 256.810343 \nL 55.053977 257.057542 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 62.545568 \nL 46.599432 184.951148 \nL 49.417614 197.936036 \nL 52.235795 199.396711 \nL 55.053977 206.173217 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 168.848491 \nL 46.599432 242.403701 \nL 49.417614 246.966588 \nL 52.235795 248.366238 \nL 55.053977 248.319778 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path clip-path=\"url(#p2a1a6d79aa)\" d=\"M 43.78125 242.609039 \nL 46.599432 248.023272 \nL 49.417614 247.950118 \nL 52.235795 249.251599 \nL 55.053977 248.999409 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 282.799219 \nL 43.78125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 322.78125 282.799219 \nL 322.78125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 282.799219 \nL 322.78125 282.799219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 10.999219 \nL 322.78125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 213.9625 77.711719 \nL 315.78125 77.711719 \nQ 317.78125 77.711719 317.78125 75.711719 \nL 317.78125 17.999219 \nQ 317.78125 15.999219 315.78125 15.999219 \nL 213.9625 15.999219 \nQ 211.9625 15.999219 211.9625 17.999219 \nL 211.9625 75.711719 \nQ 211.9625 77.711719 213.9625 77.711719 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_27\">\n     <path d=\"M 215.9625 24.097656 \nL 235.9625 24.097656 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_28\"/>\n    <g id=\"text_14\">\n     <!-- yield loss -->\n     <defs>\n      <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path id=\"DejaVuSans-32\"/>\n     </defs>\n     <g transform=\"translate(243.9625 27.597656)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"86.962891\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"148.486328\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"176.269531\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"239.746094\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"271.533203\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"299.316406\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"360.498047\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"412.597656\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_29\">\n     <path d=\"M 215.9625 38.775781 \nL 235.9625 38.775781 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_30\"/>\n    <g id=\"text_15\">\n     <!-- crop area loss -->\n     <defs>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     </defs>\n     <g transform=\"translate(243.9625 42.275781)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"93.84375\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"155.025391\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"218.501953\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"250.289062\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"311.568359\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"350.431641\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"411.955078\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"473.234375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"505.021484\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"532.804688\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"593.986328\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"646.085938\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_31\">\n     <path d=\"M 215.9625 53.453906 \nL 235.9625 53.453906 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_32\"/>\n    <g id=\"text_16\">\n     <!-- train error -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(243.9625 56.953906)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"326.074219\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"365.4375\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"404.300781\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"465.482422\" xlink:href=\"#DejaVuSans-114\"/>\n     </g>\n    </g>\n    <g id=\"line2d_33\">\n     <path d=\"M 215.9625 68.132031 \nL 235.9625 68.132031 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_34\"/>\n    <g id=\"text_17\">\n     <!-- test error -->\n     <g transform=\"translate(243.9625 71.632031)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"223.828125\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"285.351562\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"324.714844\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"363.578125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"424.759766\" xlink:href=\"#DejaVuSans-114\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p2a1a6d79aa\">\n   <rect height=\"271.8\" width=\"279\" x=\"43.78125\" y=\"10.999219\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if (test_env == 'guanabana'):\n",
        "  best_params['num_epochs'] = 100\n",
        "  y_num_id_df = combined_dfs['LABEL_NUMERIC_IDS']\n",
        "  net, preds_l, preds_h, valid_nrmse = evaluateOptimalHyperparameters(cyp_config,\n",
        "                                                                      combined_dfs,\n",
        "                                                                      country_years,\n",
        "                                                                      best_params,\n",
        "                                                                      is_validation=True,\n",
        "                                                                      early_stopping=True,\n",
        "                                                                      visualize=False)\n",
        "  print('Validation NRMSE:', round(100 * valid_nrmse, 2))\n",
        "  low_res_pred_cols =[\"id_y\", \"FYEAR\", \"YIELD\", \"YIELD_PRED\", \"CROP_AREA\", \"CROP_AREA_PRED\"]\n",
        "  low_res_pred_df = pd.DataFrame(data=preds_l, columns=low_res_pred_cols)\n",
        "  low_res_pred_df = low_res_pred_df.merge(y_num_id_df, on=[\"id_y\"]).drop(columns=[\"id_y\"])\n",
        "  low_res_pred_cols = [\"COUNTY_ID\", \"FYEAR\", \"YIELD\", \"YIELD_PRED\", \"CROP_AREA\", \"CROP_AREA_PRED\"]\n",
        "  low_res_pred_df = low_res_pred_df[low_res_pred_cols]\n",
        "\n",
        "  high_res_pred_df = pd.DataFrame(data=preds_h, columns=[\"id_y\", \"GRID_ID\", \"FYEAR\", \"YIELD_PRED\"])\n",
        "  high_res_pred_df = high_res_pred_df.merge(y_num_id_df, on=[\"id_y\"]).drop(columns=[\"id_y\"])\n",
        "  # print(high_res_pred_df.head(5))\n",
        "  yield_sel_cols = [\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\", \"YIELD\"]\n",
        "  high_res_pred_df = high_res_pred_df.merge(pd_grids_yield_df[yield_sel_cols], on=[\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\"])\n",
        "  high_res_pred_cols = [\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\", \"YIELD_PRED\", \"YIELD\"]\n",
        "  high_res_pred_df = high_res_pred_df[high_res_pred_cols]\n",
        "\n",
        "  valid_info = '\\nValidation Set NRMSEs'\n",
        "  valid_info += '\\n---------------------'\n",
        "  print('\\n', crop)\n",
        "  valid_info += '\\n' + crop\n",
        "  lres_nrmse = NormalizedRMSE(low_res_pred_df['YIELD'].values,\n",
        "                              low_res_pred_df['YIELD_PRED'].values)\n",
        "  print('\\nCOUNTY level NRMSE:', lres_nrmse)\n",
        "  valid_info += '\\nCOUNTY Level NRMSE:' + str(lres_nrmse)\n",
        "  print(low_res_pred_df.head(10))\n",
        "\n",
        "  hres_nrmse = NormalizedRMSE(high_res_pred_df['YIELD'].values,\n",
        "                              high_res_pred_df['YIELD_PRED'].values)\n",
        "  print('\\nGRID level NRMSE:', hres_nrmse)\n",
        "  valid_info += '\\nGRID level NRMSE:' + str(hres_nrmse)\n",
        "  print(high_res_pred_df.head(10))\n",
        "\n",
        "  log_fh.write(valid_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X31745bT9mqN"
      },
      "source": [
        "### Evaluate on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BOwA0Nzo9mqX",
        "outputId": "deee3a9e-3bca-465f-ccb0-01ba3373d073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NRMSE: 0.139\n",
            "Test NRMSE: 13.9\n",
            "\n",
            " soft wheat DE\n",
            "Level y NRMSE: 11.953995914369361\n",
            "  COUNTRY NUTS2_ID   FYEAR  YIELD  YIELD_PRED  CROP_AREA  CROP_AREA_PRED\n",
            "0      DE     DE11  2013.0   7.56    6.966383    95312.0    63561.125000\n",
            "1      DE     DE11  2014.0   8.29    7.078942    93025.0    64082.500000\n",
            "2      DE     DE11  2015.0   7.73    7.142239    95852.0    67834.929688\n",
            "3      DE     DE11  2016.0   6.74    7.410132    92208.0    74259.507812\n",
            "4      DE     DE11  2017.0   7.60    7.439291    87077.0    74183.351562\n",
            "5      DE     DE12  2013.0   6.72    6.570160    41521.0    39480.386719\n",
            "6      DE     DE12  2014.0   7.32    6.646784    40525.0    39001.687500\n",
            "7      DE     DE12  2015.0   6.90    6.586979    41759.0    39807.703125\n",
            "8      DE     DE12  2016.0   6.17    6.825252    40170.0    44110.730469\n",
            "9      DE     DE12  2017.0   6.91    6.841333    37933.0    42948.718750\n",
            "\n",
            "Level x NRMSE: 16.616137196497395\n",
            "  COUNTRY NUTS2_ID NUTS3_ID   FYEAR  YIELD  YIELD_PRED\n",
            "0      DE     DE11    DE118  2013.0   8.24    7.020598\n",
            "1      DE     DE11    DE118  2014.0   8.55    7.156545\n",
            "2      DE     DE11    DE118  2015.0   8.52    7.217216\n",
            "3      DE     DE11    DE118  2016.0   7.11    7.449623\n",
            "4      DE     DE11    DE118  2017.0   7.96    7.493841\n",
            "5      DE     DE11    DE119  2013.0   8.04    7.033461\n",
            "6      DE     DE11    DE119  2014.0   8.88    7.080561\n",
            "7      DE     DE11    DE119  2015.0   8.12    7.198123\n",
            "8      DE     DE11    DE119  2016.0   6.85    7.426429\n",
            "9      DE     DE11    DE119  2017.0   7.86    7.442907\n",
            "\n",
            " soft wheat ES\n",
            "Level y NRMSE: 22.120925442337242\n",
            "    COUNTRY NUTS2_ID   FYEAR  YIELD  YIELD_PRED  CROP_AREA  CROP_AREA_PRED\n",
            "151      ES     ES13  2012.0   1.24    2.114614      900.0     8697.105469\n",
            "152      ES     ES13  2013.0   2.45    1.933097      527.0     8495.670898\n",
            "153      ES     ES13  2014.0   2.45    1.693410      178.0     7407.953125\n",
            "154      ES     ES13  2015.0   2.45    1.645283      679.0     7023.464844\n",
            "155      ES     ES13  2016.0   2.45    1.713099      775.0     7287.043945\n",
            "156      ES     ES21  2012.0   6.19    5.233700    25820.0    18815.880859\n",
            "157      ES     ES21  2013.0   5.00    5.476475    24460.0    21269.458984\n",
            "158      ES     ES21  2014.0   5.00    5.589463    24705.0    20619.884766\n",
            "159      ES     ES21  2015.0   5.19    5.499013    23368.0    18854.785156\n",
            "160      ES     ES21  2016.0   6.44    5.385183    25007.0    18494.156250\n",
            "\n",
            "Level x NRMSE: 31.41410823892876\n",
            "    COUNTRY NUTS2_ID NUTS3_ID   FYEAR  YIELD  YIELD_PRED\n",
            "700      ES     ES13    ES130  2012.0   1.24    2.114614\n",
            "701      ES     ES13    ES130  2013.0   2.45    1.933097\n",
            "702      ES     ES13    ES130  2014.0   2.45    1.693410\n",
            "703      ES     ES13    ES130  2015.0   2.45    1.645283\n",
            "704      ES     ES13    ES130  2016.0   2.45    1.713099\n",
            "705      ES     ES21    ES211  2012.0   6.20    5.233700\n",
            "706      ES     ES21    ES211  2013.0   5.00    5.476475\n",
            "707      ES     ES21    ES211  2014.0   5.00    5.589463\n",
            "708      ES     ES21    ES211  2015.0   5.20    5.499013\n",
            "709      ES     ES21    ES211  2016.0   6.45    5.385183\n",
            "\n",
            " soft wheat FR\n",
            "Level y NRMSE: 12.907082031215737\n",
            "    COUNTRY NUTS2_ID   FYEAR  YIELD  YIELD_PRED  CROP_AREA  CROP_AREA_PRED\n",
            "216      FR     FR10  2011.0   7.58    8.041680   242149.0   202472.140625\n",
            "217      FR     FR10  2012.0   8.13    8.131983   236553.0   207019.046875\n",
            "218      FR     FR10  2013.0   8.38    8.094828   237289.0   208505.500000\n",
            "219      FR     FR10  2014.0   8.63    8.226760   239230.0   205783.359375\n",
            "220      FR     FR10  2015.0   8.80    8.127048   239790.0   204622.859375\n",
            "221      FR     FR10  2016.0   4.34    8.308559   243160.0   219886.453125\n",
            "222      FR     FR10  2017.0   8.00    7.799500   228570.0   175398.078125\n",
            "223      FR     FR10  2018.0   7.65    7.560225   220430.0   179511.515625\n",
            "224      FR     FRB0  2011.0   6.26    7.096362   680900.0   614828.562500\n",
            "225      FR     FRB0  2012.0   7.36    7.127866   677500.0   637214.875000\n",
            "\n",
            "Level x NRMSE: 15.85913439757215\n",
            "    COUNTRY NUTS2_ID NUTS3_ID   FYEAR  YIELD  YIELD_PRED\n",
            "900      FR     FR10    FR102  2011.0    8.0    8.034572\n",
            "901      FR     FR10    FR102  2012.0    8.1    8.129644\n",
            "902      FR     FR10    FR102  2013.0    8.4    8.080657\n",
            "903      FR     FR10    FR102  2014.0    8.8    8.222078\n",
            "904      FR     FR10    FR102  2015.0    8.9    8.113890\n",
            "905      FR     FR10    FR102  2016.0    4.0    8.309911\n",
            "906      FR     FR10    FR102  2017.0    8.1    7.794851\n",
            "907      FR     FR10    FR102  2018.0    7.7    7.557841\n",
            "908      FR     FR10    FR103  2011.0    6.9    8.102394\n",
            "909      FR     FR10    FR103  2012.0    8.1    8.148272\n",
            "\n",
            " soft wheat IT\n",
            "Level y NRMSE: 16.76586241439269\n",
            "    COUNTRY NUTS2_ID   FYEAR  YIELD  YIELD_PRED  CROP_AREA  CROP_AREA_PRED\n",
            "384      IT     ITC1  2012.0   5.70    4.859884    88982.0    78004.796875\n",
            "385      IT     ITC1  2013.0   5.26    4.980447    90810.0    90253.632812\n",
            "386      IT     ITC1  2014.0   5.66    5.214865    84632.0    87027.968750\n",
            "387      IT     ITC1  2015.0   4.96    5.211602    81826.0    83516.570312\n",
            "388      IT     ITC1  2016.0   6.07    5.281400    85805.0    89109.234375\n",
            "389      IT     ITC1  2017.0   4.85    5.458320    82156.0    93204.296875\n",
            "390      IT     ITC1  2018.0   4.40    5.323588    77580.0    91869.953125\n",
            "391      IT     ITC4  2012.0   6.09    5.617932    55915.0    60047.609375\n",
            "392      IT     ITC4  2013.0   4.91    5.779381    65198.0    65768.210938\n",
            "393      IT     ITC4  2014.0   5.72    5.711735    59528.0    59672.679688\n",
            "\n",
            "Level x NRMSE: 20.268136094753142\n",
            "     COUNTRY NUTS2_ID NUTS3_ID   FYEAR  YIELD  YIELD_PRED\n",
            "1604      IT     ITC1    ITC11  2012.0   7.27    5.005429\n",
            "1605      IT     ITC1    ITC11  2013.0   5.47    5.162341\n",
            "1606      IT     ITC1    ITC11  2014.0   5.90    5.396956\n",
            "1607      IT     ITC1    ITC11  2015.0   5.60    5.389519\n",
            "1608      IT     ITC1    ITC11  2016.0   6.00    5.447937\n",
            "1609      IT     ITC1    ITC11  2017.0   5.40    5.613962\n",
            "1610      IT     ITC1    ITC11  2018.0   4.80    5.491263\n",
            "1611      IT     ITC1    ITC12  2012.0   6.93    4.827850\n",
            "1612      IT     ITC1    ITC12  2013.0   5.80    5.016434\n",
            "1613      IT     ITC1    ITC12  2014.0   4.97    5.254001\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"320.355469pt\" version=\"1.1\" viewBox=\"0 0 337.932812 320.355469\" width=\"337.932812pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 320.355469 \nL 337.932812 320.355469 \nL 337.932812 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 282.799219 \nL 322.78125 282.799219 \nL 322.78125 10.999219 \nL 43.78125 10.999219 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 282.799219 \nL 43.78125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mc62ade002b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mc62ade002b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(35.829688 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 90.28125 282.799219 \nL 90.28125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"90.28125\" xlink:href=\"#mc62ade002b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(82.329688 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 136.78125 282.799219 \nL 136.78125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"136.78125\" xlink:href=\"#mc62ade002b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2.0 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(128.829688 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 183.28125 282.799219 \nL 183.28125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.28125\" xlink:href=\"#mc62ade002b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.5 -->\n      <g transform=\"translate(175.329688 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 229.78125 282.799219 \nL 229.78125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"229.78125\" xlink:href=\"#mc62ade002b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3.0 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(221.829688 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 276.28125 282.799219 \nL 276.28125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"276.28125\" xlink:href=\"#mc62ade002b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.5 -->\n      <g transform=\"translate(268.329687 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 322.78125 282.799219 \nL 322.78125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"322.78125\" xlink:href=\"#mc62ade002b\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4.0 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(314.829687 297.397656)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- epoch -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(168.053125 311.075781)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 282.799219 \nL 322.78125 282.799219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m7cb6cbc5ef\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7cb6cbc5ef\" y=\"282.799219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 286.598437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 228.439219 \nL 322.78125 228.439219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7cb6cbc5ef\" y=\"228.439219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 232.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 174.079219 \nL 322.78125 174.079219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7cb6cbc5ef\" y=\"174.079219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 177.878437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 119.719219 \nL 322.78125 119.719219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7cb6cbc5ef\" y=\"119.719219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(20.878125 123.518437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 65.359219 \nL 322.78125 65.359219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7cb6cbc5ef\" y=\"65.359219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(20.878125 69.158437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 10.999219 \nL 322.78125 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m7cb6cbc5ef\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 14.798438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- loss -->\n     <defs>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(14.798438 156.557031)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_27\">\n    <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 226.452058 \nL 136.78125 255.828423 \nL 229.78125 258.161026 \nL 322.78125 258.458592 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_28\">\n    <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 144.646264 \nL 136.78125 198.118042 \nL 229.78125 209.08504 \nL 322.78125 207.624858 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_29\">\n    <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 193.295491 \nL 136.78125 247.289837 \nL 229.78125 249.356664 \nL 322.78125 249.154773 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path clip-path=\"url(#p07cab13631)\" d=\"M 43.78125 242.067527 \nL 136.78125 244.439627 \nL 229.78125 242.483359 \nL 322.78125 245.007561 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 282.799219 \nL 43.78125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 322.78125 282.799219 \nL 322.78125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 282.799219 \nL 322.78125 282.799219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 10.999219 \nL 322.78125 10.999219 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 213.9625 77.711719 \nL 315.78125 77.711719 \nQ 317.78125 77.711719 317.78125 75.711719 \nL 317.78125 17.999219 \nQ 317.78125 15.999219 315.78125 15.999219 \nL 213.9625 15.999219 \nQ 211.9625 15.999219 211.9625 17.999219 \nL 211.9625 75.711719 \nQ 211.9625 77.711719 213.9625 77.711719 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_31\">\n     <path d=\"M 215.9625 24.097656 \nL 235.9625 24.097656 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_32\"/>\n    <g id=\"text_16\">\n     <!-- yield loss -->\n     <defs>\n      <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path id=\"DejaVuSans-32\"/>\n     </defs>\n     <g transform=\"translate(243.9625 27.597656)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"86.962891\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"148.486328\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"176.269531\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"239.746094\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"271.533203\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"299.316406\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"360.498047\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"412.597656\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_33\">\n     <path d=\"M 215.9625 38.775781 \nL 235.9625 38.775781 \n\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_34\"/>\n    <g id=\"text_17\">\n     <!-- crop area loss -->\n     <defs>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     </defs>\n     <g transform=\"translate(243.9625 42.275781)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"93.84375\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"155.025391\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"218.501953\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"250.289062\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"311.568359\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"350.431641\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"411.955078\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"473.234375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"505.021484\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"532.804688\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"593.986328\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"646.085938\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n    <g id=\"line2d_35\">\n     <path d=\"M 215.9625 53.453906 \nL 235.9625 53.453906 \n\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_36\"/>\n    <g id=\"text_18\">\n     <!-- train error -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(243.9625 56.953906)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"326.074219\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"365.4375\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"404.300781\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"465.482422\" xlink:href=\"#DejaVuSans-114\"/>\n     </g>\n    </g>\n    <g id=\"line2d_37\">\n     <path d=\"M 215.9625 68.132031 \nL 235.9625 68.132031 \n\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_38\"/>\n    <g id=\"text_19\">\n     <!-- test error -->\n     <g transform=\"translate(243.9625 71.632031)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"223.828125\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"285.351562\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"324.714844\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"363.578125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"424.759766\" xlink:href=\"#DejaVuSans-114\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p07cab13631\">\n   <rect height=\"271.8\" width=\"279\" x=\"43.78125\" y=\"10.999219\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if (test_env == 'guanabana'):\n",
        "  y_num_id_df = combined_dfs['LABEL_NUMERIC_IDS']\n",
        "  net, preds_l, preds_h, test_nrmse = evaluateOptimalHyperparameters(cyp_config,\n",
        "                                                                     combined_dfs,\n",
        "                                                                     country_years,\n",
        "                                                                     best_params,\n",
        "                                                                     is_validation=False,\n",
        "                                                                     early_stopping=False,\n",
        "                                                                     visualize=False)\n",
        "  print('Test NRMSE:', round(100 * test_nrmse, 2))\n",
        "  low_res_pred_cols =[\"id_y\", \"FYEAR\", \"YIELD\", \"YIELD_PRED\", \"CROP_AREA\", \"CROP_AREA_PRED\"]\n",
        "  low_res_pred_df = pd.DataFrame(data=preds_l, columns=low_res_pred_cols)\n",
        "\n",
        "  low_res_pred_df = low_res_pred_df.merge(y_num_id_df, on=[\"id_y\"]).drop(columns=[\"id_y\"])\n",
        "  low_res_pred_cols =[\"COUNTY_ID\", \"FYEAR\", \"YIELD\", \"YIELD_PRED\", \"CROP_AREA\", \"CROP_AREA_PRED\"]\n",
        "  low_res_pred_df = low_res_pred_df[low_res_pred_cols]\n",
        "\n",
        "  high_res_pred_df = pd.DataFrame(data=preds_h, columns=[\"id_y\", \"GRID_ID\", \"FYEAR\", \"YIELD_PRED\"])\n",
        "  high_res_pred_df = high_res_pred_df.merge(y_num_id_df, on=[\"id_y\"]).drop(columns=[\"id_y\"])\n",
        "  print(high_res_pred_df.head(5))\n",
        "  yield_sel_cols = [\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\", \"YIELD\"]\n",
        "  high_res_pred_df = high_res_pred_df.merge(pd_grids_yield_df[yield_sel_cols], on=[\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\"])\n",
        "  high_res_pred_cols = [\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\", \"YIELD_PRED\", \"YIELD\"]\n",
        "  high_res_pred_df = high_res_pred_df[high_res_pred_cols]\n",
        "\n",
        "  test_info = '\\nTest Set NRMSEs'\n",
        "  test_info += '\\n--------------'\n",
        "  print('\\n', crop)\n",
        "  test_info += '\\n' + crop\n",
        "  lres_nrmse = NormalizedRMSE(low_res_pred_df['YIELD'].values,\n",
        "                              low_res_pred_df['YIELD_PRED'].values)\n",
        "  print('\\nCOUNTY level NRMSE:', lres_nrmse)\n",
        "  test_info += '\\nCOUNTY Level NRMSE:' + str(lres_nrmse)\n",
        "  print(low_res_pred_df.head(10))\n",
        "\n",
        "  hres_nrmse = NormalizedRMSE(high_res_pred_df['YIELD'].values,\n",
        "                              high_res_pred_df['YIELD_PRED'].values)\n",
        "  print('\\nGRID Level NRMSE:', hres_nrmse)\n",
        "  test_info += '\\nGRID level NRMSE:' + str(hres_nrmse)\n",
        "  print(high_res_pred_df.head(10))\n",
        "\n",
        "  output_path = cyp_config['output_path']\n",
        "  high_res_pred_file = getPredictionFilename(cyp_config['crop'],\n",
        "                                             cyp_config['use_yield_trend'],\n",
        "                                             cyp_config['early_season_end_dekad'],\n",
        "                                             country=country,\n",
        "                                             spatial_level=cyp_config['input_spatial_level'],\n",
        "                                             architecture=cyp_config['architecture'])\n",
        "  high_res_pred_df.to_csv(output_path + '/' + high_res_pred_file + '.csv', index=False)\n",
        "\n",
        "  low_res_pred_file = getPredictionFilename(cyp_config['crop'],\n",
        "                                            cyp_config['use_yield_trend'],\n",
        "                                            cyp_config['early_season_end_dekad'],\n",
        "                                            country=country,\n",
        "                                            spatial_level=cyp_config['label_spatial_level'],\n",
        "                                            architecture=cyp_config['architecture'])\n",
        "\n",
        "  low_res_pred_df.to_csv(output_path + '/' + low_res_pred_file + '.csv', index=False)\n",
        "\n",
        "  log_fh.write(test_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q41axxFLsBww"
      },
      "source": [
        "### Evaluate Multiple Runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEM92cRP5bQx"
      },
      "source": [
        "#### Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb4tUKBw5bQz",
        "outputId": "d922dac7-cf2f-47bc-c580-d3d4f97a8000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------\n",
            "Training data\n",
            "----------------\n",
            "\n",
            "\n",
            "Dekadal features: WLIM_YB, WLIM_YS, WLAI, TWC, RSM, TMAX, TMIN, TAVG, PREC, CWB, FAPAR\n",
            "Other features: SM_WHC, AVG_ELEV, STD_ELEV, AVG_SLOPE, STD_SLOPE, AVG_FIELD_SIZE, STD_FIELD_SIZE, IRRIG_AREA_ALL, IRRIG_AREA90, CN_0, CN_1, CN_2, CN_3, AEZ_1761, AEZ_1810, AEZ_1842, AEZ_1845, AEZ_1892, AEZ_1932, AEZ_1957, AEZ_1960, AEZ_1976, AEZ_1984, AEZ_2030, AEZ_2034, AEZ_2057, AEZ_2075, AEZ_2107, AEZ_2135, AEZ_2137, AEZ_2150\n",
            "Trend features: YIELD-5, YIELD-4, YIELD-3, YIELD-2, YIELD-1\n",
            "Label columns: YIELD, CROP_AREA\n",
            "\n",
            "DE Training years: 2004, 2005, 2006, 2007\n",
            "\n",
            "ES Training years: 2003, 2004, 2005, 2006\n",
            "\n",
            "FR Training years: 1999, 2000, 2001, 2002, 2003, 2004, 2005\n",
            "\n",
            "IT Training years: 2000, 2001, 2002, 2003, 2004, 2005, 2006\n",
            "\n",
            "\n",
            "Dekadal data: 1882, 30, 14\n",
            "Other feature data: 357, 33\n",
            "Trend feature data: 435, 5\n",
            "Label data: 435, 5\n",
            "\n",
            "------------------\n",
            "Validation data\n",
            "------------------\n",
            "\n",
            "\n",
            "Dekadal features: WLIM_YB, WLIM_YS, WLAI, TWC, RSM, TMAX, TMIN, TAVG, PREC, CWB, FAPAR\n",
            "Other features: SM_WHC, AVG_ELEV, STD_ELEV, AVG_SLOPE, STD_SLOPE, AVG_FIELD_SIZE, STD_FIELD_SIZE, IRRIG_AREA_ALL, IRRIG_AREA90, CN_0, CN_1, CN_2, CN_3, AEZ_1761, AEZ_1810, AEZ_1842, AEZ_1845, AEZ_1892, AEZ_1932, AEZ_1957, AEZ_1960, AEZ_1976, AEZ_1984, AEZ_2030, AEZ_2034, AEZ_2057, AEZ_2075, AEZ_2107, AEZ_2135, AEZ_2137, AEZ_2150\n",
            "Trend features: YIELD-5, YIELD-4, YIELD-3, YIELD-2, YIELD-1\n",
            "Label columns: YIELD, CROP_AREA\n",
            "\n",
            "DE Validation years: 2008, 2009, 2010, 2011, 2012\n",
            "\n",
            "ES Validation years: 2007, 2008, 2009, 2010, 2011\n",
            "\n",
            "FR Validation years: 2006, 2007, 2008, 2009, 2010\n",
            "\n",
            "IT Validation years: 2007, 2008, 2009, 2010, 2011\n",
            "\n",
            "\n",
            "Dekadal data: 1748, 30, 14\n",
            "Other feature data: 357, 33\n",
            "Trend feature data: 400, 5\n",
            "Label data: 400, 5\n",
            "\n",
            "----------------\n",
            "Training data\n",
            "----------------\n",
            "\n",
            "\n",
            "Dekadal features: WLIM_YB, WLIM_YS, WLAI, TWC, RSM, TMAX, TMIN, TAVG, PREC, CWB, FAPAR\n",
            "Other features: SM_WHC, AVG_ELEV, STD_ELEV, AVG_SLOPE, STD_SLOPE, AVG_FIELD_SIZE, STD_FIELD_SIZE, IRRIG_AREA_ALL, IRRIG_AREA90, CN_0, CN_1, CN_2, CN_3, AEZ_1761, AEZ_1810, AEZ_1842, AEZ_1845, AEZ_1892, AEZ_1932, AEZ_1957, AEZ_1960, AEZ_1976, AEZ_1984, AEZ_2030, AEZ_2034, AEZ_2057, AEZ_2075, AEZ_2107, AEZ_2135, AEZ_2137, AEZ_2150\n",
            "Trend features: YIELD-5, YIELD-4, YIELD-3, YIELD-2, YIELD-1\n",
            "Label columns: YIELD, CROP_AREA\n",
            "\n",
            "DE Training years: 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012\n",
            "\n",
            "ES Training years: 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011\n",
            "\n",
            "FR Training years: 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010\n",
            "\n",
            "IT Training years: 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011\n",
            "\n",
            "\n",
            "Dekadal data: 3630, 30, 14\n",
            "Other feature data: 357, 33\n",
            "Trend feature data: 835, 5\n",
            "Label data: 835, 5\n",
            "\n",
            "-------------\n",
            "Test data:\n",
            "-------------\n",
            "\n",
            "\n",
            "Dekadal features: WLIM_YB, WLIM_YS, WLAI, TWC, RSM, TMAX, TMIN, TAVG, PREC, CWB, FAPAR\n",
            "Other features: SM_WHC, AVG_ELEV, STD_ELEV, AVG_SLOPE, STD_SLOPE, AVG_FIELD_SIZE, STD_FIELD_SIZE, IRRIG_AREA_ALL, IRRIG_AREA90, CN_0, CN_1, CN_2, CN_3, AEZ_1761, AEZ_1810, AEZ_1842, AEZ_1845, AEZ_1892, AEZ_1932, AEZ_1957, AEZ_1960, AEZ_1976, AEZ_1984, AEZ_2030, AEZ_2034, AEZ_2057, AEZ_2075, AEZ_2107, AEZ_2135, AEZ_2137, AEZ_2150\n",
            "Trend features: YIELD-5, YIELD-4, YIELD-3, YIELD-2, YIELD-1\n",
            "Label columns: YIELD, CROP_AREA\n",
            "\n",
            "DE Test years: 2013, 2014, 2015, 2016, 2017\n",
            "\n",
            "ES Test years: 2012, 2013, 2014, 2015, 2016\n",
            "\n",
            "FR Test years: 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018\n",
            "\n",
            "IT Test years: 2012, 2013, 2014, 2015, 2016, 2017, 2018\n",
            "\n",
            "\n",
            "Dekadal data: 2167, 30, 14\n",
            "Other feature data: 357, 33\n",
            "Trend feature data: 499, 5\n",
            "Label data: 499, 5\n"
          ]
        }
      ],
      "source": [
        "test_fraction = cyp_config['test_fraction']\n",
        "use_yield_trend = cyp_config['use_yield_trend']\n",
        "early_season_end = cyp_config['early_season_end_dekad']\n",
        "print_debug = cyp_config['debug_level'] > 1\n",
        "num_valid_years = 5\n",
        "\n",
        "scaler_args = {}\n",
        "train_dataset = CYPMLDataset(combined_dfs, country_years,\n",
        "                             yield_trend=use_yield_trend,\n",
        "                             early_season_end=early_season_end,\n",
        "                             is_train=True,\n",
        "                             test_fraction=test_fraction,\n",
        "                             num_folds=1, fold_iter=0,\n",
        "                             num_valid_years=num_valid_years,\n",
        "                             scaler_args=scaler_args,\n",
        "                             print_debug=print_debug,\n",
        "                             log_fh=log_fh)\n",
        "\n",
        "valid_dataset = CYPMLDataset(combined_dfs, country_years,\n",
        "                             yield_trend=use_yield_trend,\n",
        "                             early_season_end=early_season_end,\n",
        "                             is_train=False, is_validation=True,\n",
        "                             test_fraction=test_fraction,\n",
        "                             num_folds=1, fold_iter=0,\n",
        "                             num_valid_years=num_valid_years,\n",
        "                             scaler_args=scaler_args,\n",
        "                             print_debug=print_debug,\n",
        "                             log_fh=log_fh)\n",
        "\n",
        "scaler_args = {}\n",
        "train_dataset2 = CYPMLDataset(combined_dfs, country_years,\n",
        "                              yield_trend=use_yield_trend,\n",
        "                              early_season_end=early_season_end,\n",
        "                              is_train=True,\n",
        "                              test_fraction=test_fraction,\n",
        "                              num_folds=1, fold_iter=0,\n",
        "                              num_valid_years=0,\n",
        "                              scaler_args=scaler_args,\n",
        "                              print_debug=print_debug,\n",
        "                              log_fh=log_fh)\n",
        "\n",
        "test_dataset = CYPMLDataset(combined_dfs, country_years,\n",
        "                            yield_trend=use_yield_trend,\n",
        "                            early_season_end=early_season_end,\n",
        "                            is_train=False, is_validation=False,\n",
        "                            test_fraction=test_fraction,\n",
        "                            num_folds=1, fold_iter=0,\n",
        "                            num_valid_years=0,\n",
        "                            scaler_args=scaler_args,\n",
        "                            print_debug=print_debug,\n",
        "                            log_fh=log_fh)\n",
        "\n",
        "datasets = {\n",
        "    'valid' : [train_dataset, valid_dataset],\n",
        "    'test' : [train_dataset2, test_dataset]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fibd2TgP5np3"
      },
      "source": [
        "#### Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7fyEZxN5nqI"
      },
      "outputs": [],
      "source": [
        "def trainAndTest(cyp_config, best_params,\n",
        "                 train_dataset, test_dataset,\n",
        "                 early_stopping=False,\n",
        "                 visualize=False, country=None):\n",
        "  \"\"\"\n",
        "  1. Evaluate on validation data: num_valid_years = 5\n",
        "  2. Evaluate on test data: num_valid_years = 0.\n",
        "  \"\"\"\n",
        "  loss = nn.MSELoss()\n",
        "  num_epochs = best_params['num_epochs']\n",
        "  architecture = cyp_config['architecture']\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "\n",
        "  y_max = 1.0 # torch.max(train_dataset[0][3]).item()/2\n",
        "  # train_dataset is : X_ts, X_rest, X_trend.\n",
        "  # X_rest shape is (num_regions, variables). Skip TOTAL_AREA\n",
        "  train_data_item = train_dataset[0]\n",
        "  num_other_features = train_data_item[1].shape[1] - 1\n",
        "\n",
        "  # X_trend shape is (trend_window)\n",
        "  num_trend_features = train_data_item[2].shape[0]\n",
        "\n",
        "  # time series (dekadal) data is [num_regions, num_dekads, num_indicators]\n",
        "  num_ts_indicators = train_data_item[0].shape[2]\n",
        "  ts_seq_len = train_data_item[0].shape[1]\n",
        "\n",
        "  device = d2l.try_gpu()\n",
        "  net = CYPLSTMModel(num_ts_indicators,\n",
        "                     num_trend_features,\n",
        "                     num_other_features,\n",
        "                     ts_seq_len=ts_seq_len,\n",
        "                     num_outputs=2)\n",
        "\n",
        "  net = net.to(device)\n",
        "  # need to handle 64 bit values\n",
        "  net.double()\n",
        "  trainer = torch.optim.Adam(net.parameters(), lr=best_params['lr'],\n",
        "                             weight_decay=best_params['weight_decay'])\n",
        "\n",
        "  test_nrmse, epochs_run = train(net, train_dataset, train_loader, test_loader,\n",
        "                                 loss, best_params['loss_split'],\n",
        "                                 trainer, num_epochs,\n",
        "                                 early_stopping=early_stopping, device=device,\n",
        "                                 country=country, visualize=visualize, ymax=y_max)\n",
        "\n",
        "  if (early_stopping):\n",
        "    best_params['num_epochs'] = epochs_run\n",
        "\n",
        "  print('NRMSE:', round(test_nrmse, 4))\n",
        "  preds_l, preds_h, test_nrmse = evaluatePredictions(net, test_loader, device)\n",
        "\n",
        "  return net, preds_h, preds_l, test_nrmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBrlsTmc5zTl"
      },
      "source": [
        "#### Evaluate Multiple Runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5v5FuUh5zTm",
        "outputId": "5dd25386-2dd8-469e-8da0-b5539c4bded6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1239\n",
            "\n",
            "Validation NRMSE:12.387\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.488287114440771\n",
            "Level x NRMSE:16.944089684724634\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:19.862470036245934\n",
            "Level x NRMSE:25.123044320128535\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:8.858372623890096\n",
            "Level x NRMSE:12.368027989192736\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:17.244108212384308\n",
            "Level x NRMSE:20.548790127574037\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1409\n",
            "\n",
            "Test NRMSE: 14.09\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.963050746974794\n",
            "Level x NRMSE:16.674813867559674\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:22.037348141150034\n",
            "Level x NRMSE:31.32366227177441\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:12.752690072439652\n",
            "Level x NRMSE:15.349041660868911\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:18.441620323779635\n",
            "Level x NRMSE:20.96797247080136\n",
            "\n",
            "Iteration 2\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1297\n",
            "\n",
            "Validation NRMSE:12.973\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.264057343943618\n",
            "Level x NRMSE:17.870478106776144\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:23.113540506295443\n",
            "Level x NRMSE:31.465220186733333\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:10.06665030906925\n",
            "Level x NRMSE:15.53290308233942\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:17.782189245782845\n",
            "Level x NRMSE:22.935239369608436\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1428\n",
            "\n",
            "Test NRMSE: 14.28\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:12.095839212427467\n",
            "Level x NRMSE:16.802275754872323\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:21.06298414969326\n",
            "Level x NRMSE:31.783888006497204\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:13.033722927740058\n",
            "Level x NRMSE:15.62487792096516\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:18.987370708861615\n",
            "Level x NRMSE:21.43554385042221\n",
            "\n",
            "Iteration 3\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1306\n",
            "\n",
            "Validation NRMSE:13.061\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.624470056549812\n",
            "Level x NRMSE:18.742177217998492\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:23.523169795195088\n",
            "Level x NRMSE:28.024048013320545\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:9.465358792495524\n",
            "Level x NRMSE:12.299695877146055\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:17.990562169427147\n",
            "Level x NRMSE:20.75867946758005\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1413\n",
            "\n",
            "Test NRMSE: 14.13\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.971003353022912\n",
            "Level x NRMSE:16.804339066637905\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:22.393309032769203\n",
            "Level x NRMSE:32.60612311357692\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:12.88971462357109\n",
            "Level x NRMSE:15.653247265870927\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:18.148592083895135\n",
            "Level x NRMSE:21.29442616070741\n",
            "\n",
            "Iteration 4\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1259\n",
            "\n",
            "Validation NRMSE:12.593\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.750595426206084\n",
            "Level x NRMSE:18.432300289171362\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:20.98753858172369\n",
            "Level x NRMSE:26.272828174439315\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:9.121972727701278\n",
            "Level x NRMSE:12.190301327872138\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:16.493391989938416\n",
            "Level x NRMSE:19.85236858129095\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.144\n",
            "\n",
            "Test NRMSE: 14.4\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:12.667555840289129\n",
            "Level x NRMSE:17.444198199801015\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:22.50639630169157\n",
            "Level x NRMSE:31.97392232605885\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:13.113414010798639\n",
            "Level x NRMSE:15.975072545166652\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:17.448639946931294\n",
            "Level x NRMSE:20.884584020633618\n",
            "\n",
            "Iteration 5\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1231\n",
            "\n",
            "Validation NRMSE:12.312\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:10.815676189305359\n",
            "Level x NRMSE:16.628497345685574\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:22.866560526152455\n",
            "Level x NRMSE:27.48716155115281\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:8.225966625416758\n",
            "Level x NRMSE:11.821878778089141\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:18.17718165343526\n",
            "Level x NRMSE:20.99107530724903\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1411\n",
            "\n",
            "Test NRMSE: 14.11\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.71659703246798\n",
            "Level x NRMSE:16.022507565272537\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:23.02660802095318\n",
            "Level x NRMSE:34.24330555267763\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:12.929822950669458\n",
            "Level x NRMSE:15.858997208558538\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:18.317091805878245\n",
            "Level x NRMSE:20.825412446576514\n",
            "\n",
            "Iteration 6\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1299\n",
            "\n",
            "Validation NRMSE:12.992\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:12.210038532320745\n",
            "Level x NRMSE:19.47414263894126\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:21.424265275738623\n",
            "Level x NRMSE:26.085544099680305\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:9.358256297547893\n",
            "Level x NRMSE:13.349658773491296\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:16.92852972225736\n",
            "Level x NRMSE:20.442290020394807\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1446\n",
            "\n",
            "Test NRMSE: 14.46\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.201592861576389\n",
            "Level x NRMSE:16.057054654115532\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:24.620685143077456\n",
            "Level x NRMSE:37.1565419983644\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:12.019542800954902\n",
            "Level x NRMSE:15.55012142091132\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:22.96909616727178\n",
            "Level x NRMSE:24.12920448478377\n",
            "\n",
            "Iteration 7\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.125\n",
            "\n",
            "Validation NRMSE:12.505\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.858128585874303\n",
            "Level x NRMSE:18.96383343888077\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:19.897023012321714\n",
            "Level x NRMSE:25.38828345020637\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:8.607322182129645\n",
            "Level x NRMSE:13.078068469148315\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:17.114467303748455\n",
            "Level x NRMSE:20.972400094946448\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1396\n",
            "\n",
            "Test NRMSE: 13.96\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.811121661546368\n",
            "Level x NRMSE:16.63795109746161\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:23.03447011004716\n",
            "Level x NRMSE:33.346182128959306\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:12.702689227901201\n",
            "Level x NRMSE:15.468025788311097\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:17.717455070495447\n",
            "Level x NRMSE:20.38258786154651\n",
            "\n",
            "Iteration 8\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1233\n",
            "\n",
            "Validation NRMSE:12.332\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.187820152274197\n",
            "Level x NRMSE:18.237160798163146\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:20.759639961341325\n",
            "Level x NRMSE:26.946398240792714\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:9.094201311614919\n",
            "Level x NRMSE:13.29903945171851\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:16.934334136429662\n",
            "Level x NRMSE:21.56589512426754\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1431\n",
            "\n",
            "Test NRMSE: 14.31\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:12.489774984011914\n",
            "Level x NRMSE:17.296159786778677\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:22.665850664711165\n",
            "Level x NRMSE:33.466731791584635\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:12.606942852729095\n",
            "Level x NRMSE:15.447035869228438\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:18.584201454976224\n",
            "Level x NRMSE:21.538143505643166\n",
            "\n",
            "Iteration 9\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1254\n",
            "\n",
            "Validation NRMSE:12.544\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.054071494145246\n",
            "Level x NRMSE:17.878303365125234\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:23.176699302495923\n",
            "Level x NRMSE:30.81650375795818\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:9.150207197444553\n",
            "Level x NRMSE:15.351142067080493\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:17.134750531584228\n",
            "Level x NRMSE:22.467667123858416\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1401\n",
            "\n",
            "Test NRMSE: 14.01\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.60677465901254\n",
            "Level x NRMSE:16.273832398026514\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:23.010563951516065\n",
            "Level x NRMSE:33.62445163602331\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:12.990508293983762\n",
            "Level x NRMSE:15.719826149477004\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:17.83276449526216\n",
            "Level x NRMSE:21.11274912145094\n",
            "\n",
            "Iteration 10\n",
            "-------------------\n",
            "\n",
            "\n",
            "Validation Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.123\n",
            "\n",
            "Validation NRMSE:12.297\n",
            "Validation Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:11.222815784000694\n",
            "Level x NRMSE:17.604229469592763\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:19.87413006624699\n",
            "Level x NRMSE:26.69583412137241\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:9.122643701529631\n",
            "Level x NRMSE:13.030938999173287\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:17.08857748840466\n",
            "Level x NRMSE:21.929505793259576\n",
            "\n",
            "\n",
            "Test Set Evaluation\n",
            "----------------------------\n",
            "NRMSE: 0.1613\n",
            "\n",
            "Test NRMSE: 16.13\n",
            "Test Set NRMSEs\n",
            "---------------------\n",
            "soft wheat(DE)\n",
            "Level y NRMSE:12.371289772809394\n",
            "Level x NRMSE:17.31328114475045\n",
            "soft wheat(ES)\n",
            "Level y NRMSE:22.31090847439141\n",
            "Level x NRMSE:32.88161281286115\n",
            "soft wheat(FR)\n",
            "Level y NRMSE:12.23159353821522\n",
            "Level x NRMSE:16.22887893589524\n",
            "soft wheat(IT)\n",
            "Level y NRMSE:29.373206219214094\n",
            "Level x NRMSE:27.212761605745964\n",
            "\n",
            "\n",
            "Average Validation Set NRMSEs\n",
            "----------------------------\n",
            "soft wheat, DE(NUTS2): 11.448\n",
            "soft wheat, DE(NUTS3): 18.078\n",
            "soft wheat, ES(NUTS2): 21.549\n",
            "soft wheat, ES(NUTS3): 27.43\n",
            "soft wheat, FR(NUTS2): 9.107\n",
            "soft wheat, FR(NUTS3): 13.232\n",
            "soft wheat, IT(NUTS2): 17.289\n",
            "soft wheat, IT(NUTS3): 21.246\n",
            "\n",
            "\n",
            "Average Test Set NRMSEs\n",
            "----------------------------\n",
            "soft wheat, DE(NUTS2): 11.989\n",
            "soft wheat, DE(NUTS3): 16.733\n",
            "soft wheat, ES(NUTS2): 22.667\n",
            "soft wheat, ES(NUTS3): 33.241\n",
            "soft wheat, FR(NUTS2): 12.727\n",
            "soft wheat, FR(NUTS3): 15.688\n",
            "soft wheat, IT(NUTS2): 19.782\n",
            "soft wheat, IT(NUTS3): 21.978\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import statistics as stat\n",
        "\n",
        "num_iters = 10\n",
        "valid_set_lres_nrmses = []\n",
        "valid_set_hres_nrmses = []\n",
        "test_set_lres_nrmses = []\n",
        "test_set_hres_nrmses = []\n",
        "\n",
        "for i in range(1, num_iters + 1):\n",
        "  \"\"\"\n",
        "  Evaluate on validation data with early stopping\n",
        "  \"\"\"\n",
        "  iter_info = '\\n' + 'Iteration ' + str(i)\n",
        "  iter_info += '\\n-------------------'\n",
        "  print(iter_info)\n",
        "  log_fh.write(iter_info)\n",
        "\n",
        "  best_params['num_epochs'] = 100\n",
        "  valid_info = '\\n\\nValidation Set Evaluation'\n",
        "  valid_info += '\\n----------------------------'\n",
        "  print(valid_info)\n",
        "\n",
        "  y_num_id_df = combined_dfs['LABEL_NUMERIC_IDS']\n",
        "  net, preds_h, preds_l, valid_nrmse = trainAndTest(cyp_config, best_params,\n",
        "                                                    datasets['valid'][0], datasets['valid'][1],\n",
        "                                                    early_stopping=True, visualize=False, country=country)\n",
        "\n",
        "  valid_info = '\\nValidation NRMSE:' + str(round(100 * valid_nrmse, 3))\n",
        "  low_res_pred_cols =[\"id_y\", \"FYEAR\", \"YIELD\", \"YIELD_PRED\", \"CROP_AREA\", \"CROP_AREA_PRED\"]\n",
        "  pd_lres_cv_preds = pd.DataFrame(data=preds_l, columns=low_res_pred_cols)\n",
        "  pd_lres_cv_preds = pd_lres_cv_preds.merge(y_num_id_df, on=[\"id_y\"]).drop(columns=[\"id_y\"])\n",
        "  low_res_pred_cols = [\"COUNTY_ID\", \"FYEAR\", \"YIELD\", \"YIELD_PRED\", \"CROP_AREA\", \"CROP_AREA_PRED\"]\n",
        "  pd_lres_cv_preds = pd_lres_cv_preds[low_res_pred_cols]\n",
        "\n",
        "  pd_hres_cv_preds = pd.DataFrame(data=preds_h, columns=[\"id_y\", \"GRID_ID\", \"FYEAR\", \"YIELD_PRED\"])\n",
        "  pd_hres_cv_preds = pd_hres_cv_preds.merge(y_num_id_df, on=[\"id_y\"]).drop(columns=[\"id_y\"])\n",
        "  yield_sel_cols = [\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\", \"YIELD\"]\n",
        "  pd_hres_cv_preds = pd_hres_cv_preds.merge(pd_grids_yield_df[yield_sel_cols], on=[\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\"])\n",
        "  high_res_pred_cols = [\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\", \"YIELD_PRED\", \"YIELD\"]\n",
        "  pd_hres_cv_preds = pd_hres_cv_preds[high_res_pred_cols]\n",
        "\n",
        "  valid_info += '\\nValidation Set NRMSEs'\n",
        "  valid_info += '\\n---------------------'\n",
        "  valid_info += '\\n' + crop + '(US)'\n",
        "  lres_nrmse = NormalizedRMSE(pd_lres_cv_preds['YIELD'].values,\n",
        "                              pd_lres_cv_preds['YIELD_PRED'].values)\n",
        "  # print('Level y NRMSE:', lres_nrmse)\n",
        "  valid_info += '\\nLevel y NRMSE:' + str(lres_nrmse)\n",
        "  valid_set_lres_nrmses.append(lres_nrmse)\n",
        "\n",
        "  hres_nrmse = NormalizedRMSE(pd_hres_cv_preds['YIELD'].values,\n",
        "                              pd_hres_cv_preds['YIELD_PRED'].values)\n",
        "  # print('\\nLevel x NRMSE:', hres_nrmse)\n",
        "  valid_info += '\\nLevel x NRMSE:' + str(hres_nrmse)\n",
        "  valid_set_hres_nrmses.append(hres_nrmse)\n",
        "\n",
        "  print(valid_info)\n",
        "  log_fh.write(valid_info)\n",
        "\n",
        "  \"\"\"\n",
        "  Evaluate on test data with early stopping epochs from above\n",
        "  \"\"\"\n",
        "  test_info = '\\n\\nTest Set Evaluation'\n",
        "  test_info += '\\n----------------------------'\n",
        "  print(test_info)\n",
        "  net, preds_h, preds_l, test_nrmse = trainAndTest(cyp_config, best_params,\n",
        "                                                   datasets['test'][0], datasets['test'][1],\n",
        "                                                   early_stopping=False, visualize=False, country=country)\n",
        "  test_info = '\\nTest NRMSE: ' + str(round(100 * test_nrmse, 2))\n",
        "  low_res_pred_cols =[\"id_y\", \"FYEAR\", \"YIELD\", \"YIELD_PRED\", \"CROP_AREA\", \"CROP_AREA_PRED\"]\n",
        "  pd_lres_test_preds = pd.DataFrame(data=preds_l, columns=low_res_pred_cols)\n",
        "  pd_lres_test_preds = pd_lres_test_preds.merge(y_num_id_df, on=[\"id_y\"]).drop(columns=[\"id_y\"])\n",
        "  low_res_pred_cols = [\"COUNTY_ID\", \"FYEAR\", \"YIELD\", \"YIELD_PRED\", \"CROP_AREA\", \"CROP_AREA_PRED\"]\n",
        "  pd_lres_test_preds = pd_lres_test_preds[low_res_pred_cols]\n",
        "\n",
        "  pd_hres_test_preds = pd.DataFrame(data=preds_h, columns=[\"id_y\", \"GRID_ID\", \"FYEAR\", \"YIELD_PRED\"])\n",
        "  pd_hres_test_preds = pd_hres_test_preds.merge(y_num_id_df, on=[\"id_y\"]).drop(columns=[\"id_y\"])\n",
        "  yield_sel_cols = [\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\", \"YIELD\"]\n",
        "  pd_hres_test_preds = pd_hres_test_preds.merge(pd_grids_yield_df[yield_sel_cols], on=[\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\"])\n",
        "  high_res_pred_cols = [\"COUNTY_ID\", \"GRID_ID\", \"FYEAR\", \"YIELD_PRED\", \"YIELD\"]\n",
        "  pd_hres_test_preds = pd_hres_test_preds[high_res_pred_cols]\n",
        "\n",
        "  test_info += '\\nTest Set NRMSEs'\n",
        "  test_info += '\\n---------------------'\n",
        "  test_info += '\\n' + crop + '(US)'\n",
        "  lres_nrmse = NormalizedRMSE(pd_lres_test_preds['YIELD'].values,\n",
        "                              pd_lres_test_preds['YIELD_PRED'].values)\n",
        "  # print('Level y NRMSE:', lres_nrmse)\n",
        "  test_info += '\\nLevel y NRMSE:' + str(lres_nrmse)\n",
        "  test_set_lres_nrmses.append(lres_nrmse)\n",
        "\n",
        "  hres_nrmse = NormalizedRMSE(pd_hres_test_preds['YIELD'].values,\n",
        "                              pd_hres_test_preds['YIELD_PRED'].values)\n",
        "  # print('\\nLevel x NRMSE:', hres_nrmse)\n",
        "  test_info += '\\nLevel x NRMSE:' + str(hres_nrmse)\n",
        "  test_set_hres_nrmses.append(hres_nrmse)\n",
        "\n",
        "  print(test_info)\n",
        "  log_fh.write(test_info)\n",
        "\n",
        "  output_path = cyp_config['output_path']\n",
        "  high_res_pred_file = getPredictionFilename(cyp_config['crop'],\n",
        "                                             cyp_config['use_yield_trend'],\n",
        "                                             cyp_config['early_season_end_dekad'],\n",
        "                                             country=country,\n",
        "                                             spatial_level=cyp_config['input_spatial_level'],\n",
        "                                             architecture=cyp_config['architecture'])\n",
        "  pd_hres_test_preds.to_csv(output_path + '/' + high_res_pred_file + '-' + str(i) + '.csv', index=False)\n",
        "\n",
        "  low_res_pred_file = getPredictionFilename(cyp_config['crop'],\n",
        "                                            cyp_config['use_yield_trend'],\n",
        "                                            cyp_config['early_season_end_dekad'],\n",
        "                                            country=country,\n",
        "                                            spatial_level=cyp_config['label_spatial_level'],\n",
        "                                            architecture=cyp_config['architecture'])\n",
        "\n",
        "  pd_lres_test_preds.to_csv(output_path + '/' + low_res_pred_file + '-' + str(i) + '.csv', index=False)\n",
        "\n",
        "valid_info = '\\n\\nAverage Validation Set NRMSEs'\n",
        "valid_info += '\\n----------------------------'\n",
        "avg_lres_nrmse = round(stat.fmean(valid_set_lres_nrmses), 3)\n",
        "avg_hres_nrmse = round(stat.fmean(valid_set_hres_nrmses), 3)\n",
        "valid_info += '\\n' + crop + ', US' + '(' + cyp_config['label_spatial_level'] + '): ' + str(avg_lres_nrmse)\n",
        "valid_info += '\\n' + crop + ', US' + '(' + cyp_config['input_spatial_level'] + '): ' + str(avg_hres_nrmse)\n",
        "\n",
        "print(valid_info)\n",
        "log_fh.write(valid_info)\n",
        "\n",
        "test_info = '\\n\\nAverage Test Set NRMSEs'\n",
        "test_info += '\\n----------------------------'\n",
        "avg_lres_nrmse = round(stat.fmean(test_set_lres_nrmses), 3)\n",
        "avg_hres_nrmse = round(stat.fmean(test_set_hres_nrmses), 3)\n",
        "test_info += '\\n' + crop + ', US' + '(' + cyp_config['label_spatial_level'] + '): ' + str(avg_lres_nrmse)\n",
        "test_info += '\\n' + crop + ', US' + '(' + cyp_config['input_spatial_level'] + '): ' + str(avg_hres_nrmse)\n",
        "\n",
        "log_fh.write(test_info)\n",
        "print(test_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4c9w1byacMc"
      },
      "source": [
        "### Close file handle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGAK41mWwkpz"
      },
      "outputs": [],
      "source": [
        "log_fh.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZlaoUuoZC2L"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}